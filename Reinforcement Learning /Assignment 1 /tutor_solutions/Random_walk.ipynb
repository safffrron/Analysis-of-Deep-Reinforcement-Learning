{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1kSmdIAiDRvK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1kSmdIAiDRvK",
    "outputId": "62b265b1-ac64-4ca1-e518-c589e61472ad"
   },
   "outputs": [],
   "source": [
    "!pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbe57dd-0b12-4a2b-9ffd-06a6c2713145",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0bbe57dd-0b12-4a2b-9ffd-06a6c2713145",
    "outputId": "a902b2cd-8448-410c-fec1-edf9beab2379"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pygame\n",
    "import random\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import matplotlib.pyplot as plt\n",
    "from gymnasium import Env, spaces, register, make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3402050-f0c6-41f5-a482-de9f52de5b84",
   "metadata": {
    "id": "b3402050-f0c6-41f5-a482-de9f52de5b84"
   },
   "outputs": [],
   "source": [
    "class RandomWalkEnv(Env):\n",
    "    metadata = {\"render_modes\": [\"human\", \"rgb_array\"], \"render_fps\": 4}\n",
    "\n",
    "    def __init__(self, render_mode=None, size=7, slip_prob = 0.5, start_loc=1,\n",
    "                 render=False, seed=31):\n",
    "\n",
    "        self.size = size  # The size of the 1D grid\n",
    "        self.window_size = 512  # The size of the PyGame window\n",
    "\n",
    "        # We have 2 actions, corresponding to \"left\" & \"right\"\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "\n",
    "        \"\"\"\n",
    "        The following dictionary maps abstract actions from `self.action_space` to\n",
    "        the direction we will walk in if that action is taken.\n",
    "        I.e. 0 corresponds to \"left\" and 1 to \"right\".\n",
    "        \"\"\"\n",
    "        self._action_to_direction = {\n",
    "            0: -1,\n",
    "            1: 1\n",
    "        }\n",
    "\n",
    "        assert render_mode is None or render_mode in self.metadata[\"render_modes\"]\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        \"\"\"\n",
    "        If human-rendering is used, `self.window` will be a reference\n",
    "        to the window that we draw to. `self.clock` will be a clock that is used\n",
    "        to ensure that the environment is rendered at the correct framerate in\n",
    "        human-mode. They will remain `None` until human-mode is used for the\n",
    "        first time.\n",
    "        \"\"\"\n",
    "        self.window = None\n",
    "        self.clock = None\n",
    "\n",
    "        # The probability of the slip\n",
    "        self.slip_prob = slip_prob\n",
    "\n",
    "        self.start_loc = start_loc\n",
    "        self._agent_location = self.start_loc\n",
    "        self._target_location = 0\n",
    "        self._dead_state = 0\n",
    "\n",
    "        self.perform_render = render\n",
    "        self.seed = seed\n",
    "\n",
    "    @property\n",
    "    def agent_loc(self):\n",
    "        return self._agent_location\n",
    "\n",
    "    def _get_obs(self):\n",
    "        \"\"\"\n",
    "        A private function to return the locations\n",
    "        \"\"\"\n",
    "        return {\"agent\": self._agent_location, \"target\": self._target_location}\n",
    "\n",
    "\n",
    "    def _get_info(self):\n",
    "        return {\n",
    "            \"distance\": abs(self._agent_location - self._target_location)\n",
    "        }\n",
    "\n",
    "    def set_start_loc(self, start_loc=None):\n",
    "        if start_loc is not None:\n",
    "            self.start_loc = start_loc\n",
    "        self._agent_location = self.start_loc\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "\n",
    "        if self.render_mode == \"human\" and self.perform_render is True:\n",
    "            self._render_frame()\n",
    "\n",
    "        return observation, info\n",
    "\n",
    "\n",
    "    def reset(self, options=None):\n",
    "        super().reset(seed=self.seed)\n",
    "        # self._agent_location = 1\n",
    "        self.set_start_loc()\n",
    "        self._target_location = self.size-1\n",
    "        self._dead_state = 0\n",
    "\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "\n",
    "        # if self.render_mode == \"human\":\n",
    "        #     self._render_frame()\n",
    "\n",
    "        return observation, info\n",
    "\n",
    "    def step(self, action):\n",
    "\n",
    "        direction = self._action_to_direction[action]\n",
    "\n",
    "        # Now get the prob score\n",
    "        random_sample = np.random.rand()\n",
    "\n",
    "        if random_sample <= self.slip_prob:\n",
    "            # Perform slip\n",
    "            slip_direction = -direction  # Flip the action (move in the opposite direction)\n",
    "        else:\n",
    "            slip_direction = direction\n",
    "\n",
    "        prev_location = self._agent_location\n",
    "        # print(random_sample, self.slip_prob, direction, slip_direction)\n",
    "\n",
    "        # We use `np.clip` to make sure we don't leave the grid\n",
    "        # self._agent_location = np.clip(\n",
    "        #     self._agent_location + slip_direction, 0, self.size - 1\n",
    "        # )\n",
    "        self._agent_location = self._agent_location + slip_direction\n",
    "\n",
    "        # An episode is done iff the agent has reached the target or the dead_state\n",
    "        goal_reached = self._agent_location == self._target_location\n",
    "        dead_state_reached = self._agent_location == self._dead_state\n",
    "\n",
    "        terminated = False\n",
    "\n",
    "        if goal_reached or dead_state_reached:\n",
    "            terminated = True\n",
    "\n",
    "        reward = 1 if goal_reached else 0\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "        info[\"log\"] = {\"current_state\": prev_location,\n",
    "                       \"action\":action, \"direction\":direction,\n",
    "                        \"slipped_direction\":slip_direction,\n",
    "                        \"next_state\": self._agent_location}\n",
    "\n",
    "        # print(info[\"log\"])\n",
    "\n",
    "        if self.render_mode == \"human\" and self.perform_render is True:\n",
    "            self._render_frame()\n",
    "\n",
    "        # Note: truncated can be set when we have empty trajectories\n",
    "        return observation, reward, terminated, False, info\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode == \"rgb_array\":\n",
    "            return self._render_frame()\n",
    "\n",
    "    def _render_frame(self):\n",
    "\n",
    "\n",
    "        # The size of a single grid square in pixels\n",
    "        pix_square_size = (\n",
    "            self.window_size / self.size\n",
    "        )\n",
    "\n",
    "        if self.window is None and self.render_mode == \"human\":\n",
    "            pygame.init()\n",
    "            pygame.display.init()\n",
    "            self.window = pygame.display.set_mode(\n",
    "                (self.window_size, pix_square_size)\n",
    "            )\n",
    "\n",
    "        if self.clock is None and self.render_mode == \"human\":\n",
    "            self.clock = pygame.time.Clock()\n",
    "\n",
    "        canvas = pygame.Surface((self.window_size, pix_square_size))\n",
    "        canvas.fill((255, 255, 255))\n",
    "\n",
    "\n",
    "        # First we draw the target\n",
    "        pygame.draw.rect(\n",
    "            canvas,\n",
    "            (0, 255, 0),\n",
    "            pygame.Rect(\n",
    "                pix_square_size * np.array([self._target_location, 0]),\n",
    "                (pix_square_size, pix_square_size),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # First we draw the dead state\n",
    "        pygame.draw.rect(\n",
    "            canvas,\n",
    "            (255, 0, 0),\n",
    "            pygame.Rect(\n",
    "                pix_square_size * np.array([self._dead_state, 0]),\n",
    "                (pix_square_size, pix_square_size),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # Now we draw the agent\n",
    "        pygame.draw.circle(\n",
    "            canvas,\n",
    "            (0, 0, 255),\n",
    "            (np.array([self._agent_location, 0]) + 0.5) * pix_square_size,\n",
    "            pix_square_size / 3,\n",
    "        )\n",
    "\n",
    "        # Finally, add some gridlines\n",
    "        for x in range(self.size + 1):\n",
    "            pygame.draw.line(\n",
    "                canvas,\n",
    "                0,\n",
    "                (pix_square_size * x, 0),\n",
    "                (pix_square_size * x, self.window_size),\n",
    "                width=3,\n",
    "            )\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            # The following line copies our drawings from `canvas` to the visible window\n",
    "            self.window.blit(canvas, canvas.get_rect())\n",
    "            pygame.event.pump()\n",
    "            pygame.display.update()\n",
    "\n",
    "            # We need to ensure that human-rendering occurs at the predefined framerate.\n",
    "            # The following line will automatically add a delay to keep the framerate stable.\n",
    "            self.clock.tick(self.metadata[\"render_fps\"])\n",
    "        else:  # rgb_array\n",
    "            return np.transpose(\n",
    "                np.array(pygame.surfarray.pixels3d(canvas)), axes=(1, 0, 2)\n",
    "            )\n",
    "\n",
    "    def close(self):\n",
    "        if self.window is not None:\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e0f4cd-f71a-481f-a4c7-d3f101900286",
   "metadata": {
    "id": "40e0f4cd-f71a-481f-a4c7-d3f101900286"
   },
   "outputs": [],
   "source": [
    "# Register the custom environment\n",
    "# register(id='RandomWalk-v0', entry_point=RandomWalkEnv)\n",
    "\n",
    "# # Create and use the environment\n",
    "# env = make('RandomWalk-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fc50dd-49eb-4997-883c-ebbe884e9207",
   "metadata": {
    "id": "c8fc50dd-49eb-4997-883c-ebbe884e9207"
   },
   "outputs": [],
   "source": [
    "environment = RandomWalkEnv(render_mode=\"human\", size=7, start_loc=3, slip_prob=0.5, render=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be07a023-f2d0-44da-b4b8-1c21b4fd8276",
   "metadata": {
    "id": "be07a023-f2d0-44da-b4b8-1c21b4fd8276"
   },
   "source": [
    "### Consider the actions based on the policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df89148-6357-4b07-934d-487c57481e1a",
   "metadata": {
    "id": "1df89148-6357-4b07-934d-487c57481e1a"
   },
   "outputs": [],
   "source": [
    "NUM_STATES = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed368ad-00f7-47b1-b91a-6c865f9480e4",
   "metadata": {
    "id": "5ed368ad-00f7-47b1-b91a-6c865f9480e4"
   },
   "outputs": [],
   "source": [
    "# For the left and right state make it as slippery\n",
    "def get_policy(state=None):\n",
    "    # policy = dict()\n",
    "    # policy[0] = [0,0]\n",
    "    # policy[NUM_STATES-1] = [0,0]\n",
    "    # for val in range(1, NUM_STATES-1):\n",
    "    #     policy[val] = [0.75, 0.25]\n",
    "    # policy\n",
    "    # return policy\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa382ce-0ffa-44b8-a996-caa2b0efde12",
   "metadata": {
    "id": "baa382ce-0ffa-44b8-a996-caa2b0efde12"
   },
   "outputs": [],
   "source": [
    "def generate_trajectory(env, maxSteps, policy_fn):\n",
    "    trajectory = []\n",
    "    observation, info = env.reset()\n",
    "    init = random.choice(list(range(1, environment.size-1)))\n",
    "    # print(init)\n",
    "    env.set_start_loc(init)\n",
    "    state = env.agent_loc\n",
    "\n",
    "    for _ in range(maxSteps):\n",
    "        # action = random.choices([0, 1], weights=policy[state])[0]\n",
    "        action = policy_fn(state)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        next_state = observation[\"agent\"]\n",
    "\n",
    "        # Append the experience tuple (state, action, reward, next_state, done) to the trajectory\n",
    "        trajectory.append((state, action, reward, next_state, terminated))\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "        if terminated:\n",
    "            return trajectory\n",
    "\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99562fe-6ee9-4780-99ef-31201b4dde3d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a99562fe-6ee9-4780-99ef-31201b4dde3d",
    "outputId": "d942264a-67ea-4628-a103-ea6bd918b1c0"
   },
   "outputs": [],
   "source": [
    "generate_trajectory(environment, 10, get_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce46e23-37fb-4203-bc78-59770d73b97b",
   "metadata": {
    "id": "dce46e23-37fb-4203-bc78-59770d73b97b"
   },
   "source": [
    "## Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426a8636-0e5d-4a80-82b0-7282c7e0524c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "id": "426a8636-0e5d-4a80-82b0-7282c7e0524c",
    "outputId": "d2084cab-2ea7-4d92-ec4b-266bd5c1ed6a"
   },
   "outputs": [],
   "source": [
    "def decayAlpha(initialValue, finalValue, maxSteps, decayType):\n",
    "    \"\"\"\n",
    "    Decay the step size parameter (α) from initialValue to finalValue over maxSteps steps.\n",
    "\n",
    "    Args:\n",
    "        initialValue: Initial value of the step size parameter.\n",
    "        finalValue: Final value of the step size parameter.\n",
    "        maxSteps: Maximum number of steps the step parameter should decay for.\n",
    "        decayType: Type of decay, either 'linear' or 'exponential'.\n",
    "\n",
    "    Returns:\n",
    "        List of step size parameter values over time.\n",
    "    \"\"\"\n",
    "    if decayType not in ['linear', 'exponential']:\n",
    "        raise ValueError(\"Invalid decayType. Should be 'linear' or 'exponential'.\")\n",
    "\n",
    "    if decayType == 'linear':\n",
    "        alpha_values = np.linspace(initialValue, finalValue, maxSteps)\n",
    "    else:  # Exponential decay\n",
    "        decay_factor = (finalValue / initialValue) ** (1 / (maxSteps -1))\n",
    "        alpha_values = [initialValue * (decay_factor ** t) for t in range(maxSteps)]\n",
    "\n",
    "    return alpha_values\n",
    "\n",
    "# Test the function with linear decay\n",
    "initial_alpha = 0.1\n",
    "final_alpha = 0.01\n",
    "max_steps = 100\n",
    "decayTypes = ['linear', 'exponential']\n",
    "\n",
    "alphas_linear = decayAlpha(initial_alpha, final_alpha,\n",
    "                           max_steps, decayType='linear')\n",
    "alphas_exp = decayAlpha(initial_alpha, final_alpha,\n",
    "                           max_steps, decayType='exponential')\n",
    "\n",
    "\n",
    "print(alphas_linear[-1])\n",
    "print(alphas_exp[-1])\n",
    "print(\"#################\")\n",
    "\n",
    "print(alphas_linear[0])\n",
    "print(alphas_exp[0])\n",
    "print(\"#################\")\n",
    "\n",
    "print(len(alphas_exp))\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(alphas_linear, label='Linear Decay')\n",
    "plt.plot(alphas_exp, label='Exponential Decay')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Alpha Value')\n",
    "plt.legend()\n",
    "plt.title('Decay of Alpha over Time Steps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4f1204-3429-431c-a1f4-458aa22ca60f",
   "metadata": {
    "id": "1a4f1204-3429-431c-a1f4-458aa22ca60f"
   },
   "source": [
    "### Monte Carlo Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586a175f-a1ef-48f4-b0d1-100c75eb7444",
   "metadata": {
    "id": "586a175f-a1ef-48f4-b0d1-100c75eb7444"
   },
   "outputs": [],
   "source": [
    "def monteCarloPrediction(env, gamma, maxSteps, max_episodes, alpha_values,\n",
    "                         visitType=\"FVMC\"):\n",
    "    if visitType not in ['FVMC', 'EVMC']:\n",
    "        raise ValueError(\"Invalid visitType. Should be 'FVMC' or 'EVMC'.\")\n",
    "    # Initialize state value estimates\n",
    "    V = np.zeros(env.size)\n",
    "    V_episodes = np.zeros((max_episodes, env.size))\n",
    "    GT_over_episodes_sum = np.zeros((max_episodes, env.size))\n",
    "    for episode in range(max_episodes):\n",
    "        # Generate trajectory\n",
    "        # print(f\"Episode: {episode}\\n\")\n",
    "        visited = np.zeros(env.size)\n",
    "        trajectory = generate_trajectory(env, maxSteps, get_policy)\n",
    "        # print(trajectory, \"\\n\\n\")\n",
    "        # print(trajectory)\n",
    "        if not trajectory:\n",
    "            continue  # Discard incomplete episodes\n",
    "        G = 0\n",
    "        for i, (s, a, r, _s, _) in enumerate(trajectory):\n",
    "            if visitType == \"FVMC\" and visited[s] != 0:\n",
    "                continue\n",
    "            G = sum(((gamma**(j-i)) * trajectory[j][2]) for j in range(i, len(trajectory)))\n",
    "            GT_over_episodes_sum[episode][s] += G\n",
    "            visited[s] += 1\n",
    "            # G = gamma * returns + r\n",
    "            #updates first visit\n",
    "            V[s] = V[s] + (alpha_values[episode] * (G - V[s]))\n",
    "        if visitType == \"EVMC\":\n",
    "            for s in range(env.size):\n",
    "                if visited[s] > 0:\n",
    "                    GT_over_episodes_sum[episode][s] /= visited[s]\n",
    "                    #update for every visit\n",
    "                    V[s] = V[s] + (alpha_values[episode] * (GT_over_episodes_sum[episode][s] - V[s]))\n",
    "        V_episodes[episode] = V\n",
    "    return V, V_episodes, GT_over_episodes_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e60b01-bc2c-4743-b264-dcab65fd507d",
   "metadata": {
    "id": "88e60b01-bc2c-4743-b264-dcab65fd507d"
   },
   "outputs": [],
   "source": [
    "MAX_EPISODES = 10000\n",
    "MAX_STEPS = 1000\n",
    "GAMMA = 0.99\n",
    "ALPHA_INIT = 0.1\n",
    "ALPHA_FIN = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6cb0bb-abd0-44c6-9eec-62c6f247c028",
   "metadata": {
    "id": "7e6cb0bb-abd0-44c6-9eec-62c6f247c028"
   },
   "outputs": [],
   "source": [
    "alpha_values = decayAlpha(ALPHA_INIT, ALPHA_FIN, MAX_EPISODES, \"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d62e4e-297c-404f-8c28-e1eb76812115",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a4d62e4e-297c-404f-8c28-e1eb76812115",
    "outputId": "9e8970b4-a7d7-46c1-fa99-e6a987496ef4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "state_values, state_values_per_episode, gt_per_episode = monteCarloPrediction(environment,\n",
    "                                                              GAMMA,\n",
    "                                                              MAX_STEPS,\n",
    "                                                              MAX_EPISODES,\n",
    "                                                              alpha_values)\n",
    "print(\"Estimated State Values:\", state_values)\n",
    "print(\"###############\")\n",
    "print()\n",
    "state_values_per_episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b477f5-9e9c-431b-9c6b-8877d88c842e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "14b477f5-9e9c-431b-9c6b-8877d88c842e",
    "outputId": "6fdde0c5-ddbe-4b76-af2e-c85b049417df"
   },
   "outputs": [],
   "source": [
    "gt_per_episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce772a85-5fdb-4e85-aa0d-4bd2cf1ab076",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ce772a85-5fdb-4e85-aa0d-4bd2cf1ab076",
    "outputId": "d373e8a1-3165-452d-b551-85fccc4822ab"
   },
   "outputs": [],
   "source": [
    "visitTypes = ['FVMC', 'EVMC']\n",
    "for visitType in visitTypes:\n",
    "    V = monteCarloPrediction(environment, GAMMA, MAX_STEPS, MAX_EPISODES, alpha_values, visitType)\n",
    "    print(f\"Estimated State Values using {visitType.capitalize()} Visit Monte Carlo Prediction:\")\n",
    "    print(V[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f56cd1-f26f-4019-9321-af84b56bf3ba",
   "metadata": {
    "id": "e9f56cd1-f26f-4019-9321-af84b56bf3ba"
   },
   "source": [
    "### Temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeb9b90-c192-4818-a622-f23262e8012f",
   "metadata": {
    "id": "1eeb9b90-c192-4818-a622-f23262e8012f"
   },
   "outputs": [],
   "source": [
    "def TemporalDifferencePrediction(env, gamma, alpha_values, max_episodes):\n",
    "\n",
    "    # Initialize state values\n",
    "    V = np.zeros(env.size)\n",
    "    V_episodes = np.zeros((max_episodes, env.size))\n",
    "    GT_over_episodes_sum = np.zeros((max_episodes, env.size))\n",
    "\n",
    "    # Loop over episodes\n",
    "    for episode in range(max_episodes):\n",
    "\n",
    "        # print(f\"Episode : {episode}\")\n",
    "        state_visited_count = np.zeros(env.size)        \n",
    "\n",
    "        observation, info = env.reset()\n",
    "        init = random.choice(list(range(1, environment.size-1)))\n",
    "        env.set_start_loc(init)\n",
    "        state = env.agent_loc\n",
    "        done = False\n",
    "\n",
    "        # Loop until episode terminates\n",
    "        while not done:\n",
    "            # Select action using policy\n",
    "            action = get_policy()\n",
    "\n",
    "            observation, r, terminated, truncated, info = env.step(action)\n",
    "            _s = observation[\"agent\"]\n",
    "\n",
    "            # Append the experience tuple (state, action, reward, next_state, done) to the trajectory\n",
    "            # print(state, action, r, _s, terminated)\n",
    "\n",
    "            td_target = r\n",
    "\n",
    "            if not terminated:\n",
    "                td_target = td_target + (gamma * V[_s])\n",
    "\n",
    "            GT_over_episodes_sum[episode][state] += td_target\n",
    "            td_error = td_target - V[state]\n",
    "            V[state] = V[state] + (alpha_values[episode] * td_error)\n",
    "            state = _s\n",
    "\n",
    "            state_visited_count[state] += 1\n",
    "            # print(state)\n",
    "\n",
    "            done = terminated        \n",
    "\n",
    "        for s in range(env.size):\n",
    "            if state_visited_count[s] > 0:\n",
    "                GT_over_episodes_sum[episode][s] /= state_visited_count[s]        \n",
    "\n",
    "\n",
    "        V_episodes[episode] = V\n",
    "\n",
    "    return V, V_episodes, GT_over_episodes_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d77b5c9-e36d-41f3-b77d-13e80b6ac8e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2d77b5c9-e36d-41f3-b77d-13e80b6ac8e5",
    "outputId": "14578b0c-5128-4a26-e70b-68058f0be31f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test the algorithm for RWE using Temporal Difference Prediction\n",
    "V_td, V_td_per_episode, gt_per_episode = TemporalDifferencePrediction(environment, GAMMA,\n",
    "                                    alpha_values, 1000)\n",
    "print(\"Estimated State Values using Temporal Difference Prediction:\")\n",
    "print(V_td)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44b0df8-54ff-4431-a4ea-d4b940e511a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_episodes(data, true, environment, total_episodes=500, period=50, name=\"MC-FVMC\", log_scale=False):\n",
    "    for episode_range_low in range(0, total_episodes, period):\n",
    "        episode_range_high = episode_range_low + period\n",
    "    \n",
    "        for i in range(1, environment.size-1):\n",
    "            plt.plot(range(episode_range_low, episode_range_high), data[episode_range_low:episode_range_high, i], label=f'State {i}')\n",
    "    \n",
    "            plt.plot(range(episode_range_low, episode_range_high), [true[i] for _ in range(episode_range_low, episode_range_high)],\n",
    "                     label=f'True Estimate - State{i}', linestyle='--', color='red')\n",
    "    \n",
    "        plt.title(f'{name} Estimate - Episode {episode_range_low}-{episode_range_high}')\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Value Estimate')\n",
    "        if log_scale:\n",
    "            plt.xscale('log')        \n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    for i in range(1, environment.size-1):\n",
    "        plt.plot(range(0, total_episodes), data[:, i], label=f'State {i}')\n",
    "        \n",
    "        plt.plot(range(0, total_episodes), [true[i] for _ in range(0, 500)],\n",
    "             label=f'True Estimate - State{i}', linestyle='--', color='red')\n",
    "    \n",
    "    plt.title(f'{name} Estimate - Episode 0-500')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Value Estimate')\n",
    "    if log_scale:\n",
    "        plt.xscale('log')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a416669f-f446-4fb5-9702-e79b890ba829",
   "metadata": {
    "id": "a416669f-f446-4fb5-9702-e79b890ba829"
   },
   "source": [
    "## Question 5 : MC-FVMC for non terminal states. 500 episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f9b46a-1eda-4943-8951-01e28b7505da",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "99f9b46a-1eda-4943-8951-01e28b7505da",
    "outputId": "13fe18cf-7670-4b14-e9ed-7d022a74eecd"
   },
   "outputs": [],
   "source": [
    "alpha_values = decayAlpha(0.5, 0.01,250, decayType='exponential')\n",
    "alpha_values = alpha_values + [alpha_values[-1]]*250\n",
    "len(alpha_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a665d541-29fb-4563-b48a-14a6711fe640",
   "metadata": {
    "id": "a665d541-29fb-4563-b48a-14a6711fe640",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "V, V_per_episode, _ = monteCarloPrediction(environment, GAMMA, 200, 500, alpha_values, \"FVMC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c89fa2f-a685-447b-acef-834cb54427a6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2c89fa2f-a685-447b-acef-834cb54427a6",
    "outputId": "3878eb2d-7b7a-4546-b222-de140e4763b7"
   },
   "outputs": [],
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f6464b-32ce-4835-843e-bf5cd1a45ab0",
   "metadata": {
    "id": "36f6464b-32ce-4835-843e-bf5cd1a45ab0"
   },
   "outputs": [],
   "source": [
    "# true_values = [0, 1/6, 2/6, 3/6, 4/6, 5/6, 0]\n",
    "true_values = [0,0.15008, 0.3032, 0.46244,0.63103,0.81236,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeaacef-ee6c-472e-b472-e5aacb771a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_episodes(V_per_episode, true_values, environment, total_episodes=500, period=50, name=\"MC-FVMC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091731aa-9480-4f67-a343-320f48094d45",
   "metadata": {
    "id": "091731aa-9480-4f67-a343-320f48094d45"
   },
   "source": [
    "## Question 6 : MC-EVMC for non terminal states. 500 episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49b4a0f-aff6-4be5-915e-c244153cd00c",
   "metadata": {
    "id": "c49b4a0f-aff6-4be5-915e-c244153cd00c"
   },
   "outputs": [],
   "source": [
    "V, V_per_episode, _ = monteCarloPrediction(environment, GAMMA, 200, 500, alpha_values, \"EVMC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9444d442-20ff-4b9f-adc4-1ea4323df742",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9444d442-20ff-4b9f-adc4-1ea4323df742",
    "outputId": "ff703d0f-1641-49bb-c069-9a81cbd71956",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_episodes(V_per_episode, true_values, environment, total_episodes=500, period=50, name=\"MC-EVMC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8ca110-32ff-458e-9129-04c7cebb29cc",
   "metadata": {
    "id": "2e8ca110-32ff-458e-9129-04c7cebb29cc"
   },
   "source": [
    "## Question 7: TD with 500 episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637ca5d8-6ce0-48bb-90a1-e60ec5ca641d",
   "metadata": {
    "id": "637ca5d8-6ce0-48bb-90a1-e60ec5ca641d"
   },
   "outputs": [],
   "source": [
    "V_td, V_td_per_episode, _ = TemporalDifferencePrediction(environment, GAMMA,\n",
    "                                    alpha_values, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeef79f8-68e9-4385-ad48-bf71332f8395",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "aeef79f8-68e9-4385-ad48-bf71332f8395",
    "outputId": "8541f7eb-36b3-429d-a8fe-b28e9fc5b4f5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_episodes(V_td_per_episode, true_values, environment, total_episodes=500, period=50, name=\"TD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69380197-50c6-48ca-80dc-2b22afc7a17d",
   "metadata": {
    "id": "69380197-50c6-48ca-80dc-2b22afc7a17d"
   },
   "source": [
    "## Question 8 : Smoother Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899806fe-189d-4d48-94f5-7c6a775e9d0e",
   "metadata": {
    "id": "899806fe-189d-4d48-94f5-7c6a775e9d0e"
   },
   "outputs": [],
   "source": [
    "possible_seeds = [27, 36, 45, 64, 67]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97106965-589f-458e-bd9e-e77d48127e1e",
   "metadata": {
    "id": "97106965-589f-458e-bd9e-e77d48127e1e"
   },
   "source": [
    "### MC-FVMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe13c27-b617-4f00-a6c6-14e07fc031b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "dfe13c27-b617-4f00-a6c6-14e07fc031b1",
    "outputId": "8969619e-bfab-479e-f9d2-da637ccaf44f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum_over_V_per_episode = None\n",
    "for seed in possible_seeds:\n",
    "    env1 = RandomWalkEnv(render_mode=\"human\", size=7, start_loc=3, slip_prob=0.5,\n",
    "                         render=False, seed=seed)\n",
    "    V, V_per_episode, _ = monteCarloPrediction(env1, GAMMA, 200, 500, alpha_values, \"FVMC\")\n",
    "\n",
    "    if sum_over_V_per_episode is None:\n",
    "        sum_over_V_per_episode = V_per_episode\n",
    "    else:\n",
    "        sum_over_V_per_episode += V_per_episode\n",
    "\n",
    "sum_over_V_per_episode /= len(possible_seeds)\n",
    "\n",
    "plot_episodes(sum_over_V_per_episode, true_values, environment, total_episodes=500, period=50, name=\"MC-FVMC Averaged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4557c25-f48a-4ea0-a05e-7a337974dd04",
   "metadata": {
    "id": "a4557c25-f48a-4ea0-a05e-7a337974dd04"
   },
   "source": [
    "### MC-EVMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0f5120-ec7d-47cc-91b0-7b22e9e8aa30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4f0f5120-ec7d-47cc-91b0-7b22e9e8aa30",
    "outputId": "370c921e-bf80-42f5-cda8-8b76628dd898",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum_over_V_per_episode = None\n",
    "for seed in possible_seeds:\n",
    "    env1 = RandomWalkEnv(render_mode=\"human\", size=7, start_loc=3, slip_prob=0.5,\n",
    "                         render=False, seed=seed)\n",
    "    V, V_per_episode, _ = monteCarloPrediction(env1, GAMMA, 200, 500, alpha_values, \"EVMC\")\n",
    "\n",
    "    if sum_over_V_per_episode is None:\n",
    "        sum_over_V_per_episode = V_per_episode\n",
    "    else:\n",
    "        sum_over_V_per_episode += V_per_episode\n",
    "\n",
    "sum_over_V_per_episode /= len(possible_seeds)\n",
    "\n",
    "\n",
    "plot_episodes(sum_over_V_per_episode, true_values, environment, total_episodes=500, period=50, name=\"MC-EVMC Averaged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cfb608-3f32-470e-8a6d-ca3e935b7ea5",
   "metadata": {
    "id": "60cfb608-3f32-470e-8a6d-ca3e935b7ea5"
   },
   "source": [
    "### TD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6515e867-091b-4bbb-a7e8-2c88c5203cef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6515e867-091b-4bbb-a7e8-2c88c5203cef",
    "outputId": "e9ab526d-cecd-44cb-b939-931ac998bd22",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum_over_V_per_episode = None\n",
    "for seed in possible_seeds:\n",
    "    env1 = RandomWalkEnv(render_mode=\"human\", size=7, start_loc=3, slip_prob=0.5,\n",
    "                         render=False, seed=seed)\n",
    "    V_td, V_td_per_episode, _ = TemporalDifferencePrediction(env1, GAMMA,\n",
    "                                    alpha_values, 500)\n",
    "\n",
    "    if sum_over_V_per_episode is None:\n",
    "        sum_over_V_per_episode = V_td_per_episode\n",
    "    else:\n",
    "        sum_over_V_per_episode += V_td_per_episode\n",
    "\n",
    "sum_over_V_per_episode /= len(possible_seeds)\n",
    "\n",
    "\n",
    "plot_episodes(sum_over_V_per_episode, true_values, environment, total_episodes=500, period=50, name=\"TD Averaged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff99195c-63aa-4ceb-bf17-4c44973a3802",
   "metadata": {
    "id": "ff99195c-63aa-4ceb-bf17-4c44973a3802"
   },
   "source": [
    "## Question - 9 - MC - FVMC with logscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859519f5-91e8-444d-8655-d9c642b7cfe5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "859519f5-91e8-444d-8655-d9c642b7cfe5",
    "outputId": "18e2472d-41cc-485f-ec95-4ad5804464e6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "V, V_per_episode, _ = monteCarloPrediction(environment, GAMMA, 200, 500, alpha_values, \"FVMC\")\n",
    "\n",
    "plot_episodes(V_per_episode, true_values, environment, total_episodes=500, period=50, name=\"MC-FVMC\", log_scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28ae257-836d-4121-90b7-34e16a41c40a",
   "metadata": {
    "id": "f28ae257-836d-4121-90b7-34e16a41c40a"
   },
   "source": [
    "## Question - 10 - MC - EVMC with logscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ad115d-b045-4db6-9205-ac15bfbbe95a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "94ad115d-b045-4db6-9205-ac15bfbbe95a",
    "outputId": "9a813c8b-ebe2-4def-94af-17777d0c9f79",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "V, V_per_episode, _ = monteCarloPrediction(environment, GAMMA, 200, 500, alpha_values, \"EVMC\")\n",
    "\n",
    "plot_episodes(V_per_episode, true_values, environment, total_episodes=500, period=50, name=\"MC-EVMC Log\", log_scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17605c8-7571-456c-8dc1-90935eb0cf2e",
   "metadata": {
    "id": "e17605c8-7571-456c-8dc1-90935eb0cf2e"
   },
   "source": [
    "## Question - 11 - TD with logscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0928ab34-fe45-43b0-8302-ebe7ce6ad170",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0928ab34-fe45-43b0-8302-ebe7ce6ad170",
    "outputId": "98e486ed-48eb-4695-9da1-c78c2eca6c41",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "V, V_per_episode, _ = TemporalDifferencePrediction(env1, GAMMA, alpha_values, 500)\n",
    "\n",
    "plot_episodes(V_per_episode, true_values, environment, total_episodes=500, period=50, name=\"TD Log\", log_scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced6527a-c9af-4bd2-ae9d-38b97f844059",
   "metadata": {
    "id": "ced6527a-c9af-4bd2-ae9d-38b97f844059"
   },
   "source": [
    "## Question - 13 - MC-FVMC - Target Value (Gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ace7f8f-3bb8-47e9-973a-d750233b69f5",
   "metadata": {
    "id": "8ace7f8f-3bb8-47e9-973a-d750233b69f5"
   },
   "outputs": [],
   "source": [
    "state = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f549cf9a-d75a-42b4-b07f-e6e4b8a67196",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "id": "f549cf9a-d75a-42b4-b07f-e6e4b8a67196",
    "outputId": "9af05083-59ff-421a-97dd-e24cda9fc97b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, _, gt_per_episode = monteCarloPrediction(environment, GAMMA, 200, 500, alpha_values, \"FVMC\")\n",
    "\n",
    "gt_state_per_episode = gt_per_episode[:, state].flatten()\n",
    "\n",
    "values = []\n",
    "episodes = []\n",
    "\n",
    "for episode, val in enumerate(gt_state_per_episode):\n",
    "    episodes.append(episode)\n",
    "    values.append(val)\n",
    "\n",
    "print(0.5 * state / (environment.size - 1))\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(episodes, values)\n",
    "plt.axhline(y=0.63103, color='r', linestyle='--', label='Optimal Value') #CHECK is this the optimal value?\n",
    "plt.title(f'MC-FVMC Estimate - State {state}')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Target Value (Gt)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f77f54-e191-4687-8896-8286312fbafc",
   "metadata": {
    "id": "15f77f54-e191-4687-8896-8286312fbafc"
   },
   "source": [
    "## Question - 14 - MC-EVMC - Target Value (Gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a39610-3754-410d-9da4-08d525daaf45",
   "metadata": {
    "id": "d3a39610-3754-410d-9da4-08d525daaf45"
   },
   "outputs": [],
   "source": [
    "state = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06baf8f3-ffe7-442d-97a6-09e403497c8b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "06baf8f3-ffe7-442d-97a6-09e403497c8b",
    "outputId": "adc9c5b8-0514-43f3-9495-c5ed17404ecd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, _, gt_per_episode = monteCarloPrediction(environment, GAMMA, 200, 500, alpha_values, \"EVMC\")\n",
    "\n",
    "gt_state_per_episode = gt_per_episode[:, state].flatten()\n",
    "\n",
    "values = []\n",
    "episodes = []\n",
    "\n",
    "for episode, val in enumerate(gt_state_per_episode):\n",
    "    if val != 0:\n",
    "        episodes.append(episode)\n",
    "        values.append(val)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(episodes, values)\n",
    "plt.axhline(y=0.63103, color='r', linestyle='--', label='Optimal Value')\n",
    "plt.title(f'MC-EVMC Estimate - State {state}')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Target Value (Gt)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d76f09-5335-45d5-8bbb-ec8f075cc3b7",
   "metadata": {
    "id": "80d76f09-5335-45d5-8bbb-ec8f075cc3b7"
   },
   "source": [
    "## Question - 15 - TD - Target Value (Gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80850cfd-f903-40cd-837a-a5af8af46502",
   "metadata": {
    "id": "80850cfd-f903-40cd-837a-a5af8af46502"
   },
   "outputs": [],
   "source": [
    "state = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ba8760-9add-4c2e-a02f-d8c8f28c73cb",
   "metadata": {
    "id": "26ba8760-9add-4c2e-a02f-d8c8f28c73cb",
    "outputId": "d6d90b22-3643-4071-e4ce-d32d066be702",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, _, gt_per_episode = TemporalDifferencePrediction(env1, GAMMA, alpha_values, 500)\n",
    "\n",
    "gt_state_per_episode = gt_per_episode[:, state].flatten()\n",
    "\n",
    "values = []\n",
    "episodes = []\n",
    "\n",
    "for episode, val in enumerate(gt_state_per_episode):\n",
    "    if val != 0:\n",
    "        episodes.append(episode)\n",
    "        values.append(val)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(episodes, values)\n",
    "plt.axhline(y=0.63103, color='r', linestyle='--', label='Optimal Value')\n",
    "plt.title(f'TD Estimate - State {state}')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Target Value (Gt)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8154ab70-0b45-48db-b180-96ed69b58edc",
   "metadata": {
    "id": "8154ab70-0b45-48db-b180-96ed69b58edc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
