{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fcuv4vY6u7UR",
    "outputId": "59b941a3-b8b6-41f4-8be7-2cddd249a2cb"
   },
   "outputs": [],
   "source": [
    "!pip install gymnasium scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import random\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from scipy.stats import bernoulli\n",
    "from gymnasium import Env, register\n",
    "from gymnasium.spaces import  Discrete\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UhNe6senlYVa"
   },
   "outputs": [],
   "source": [
    "class RandomMaze(Env):\n",
    "    def __init__(self,params):\n",
    "        # action space left =0,up=1,right=2,down=3\n",
    "        self.action_space = Discrete(4)\n",
    "        # state spaces are 3,7-terminal, 5 wall, rest all non terminal\n",
    "        self.observation_space=Discrete(12)\n",
    "        # initial state is 8\n",
    "        self.startState=params[\"startState\"]\n",
    "        self.state=self.startState\n",
    "        # prob of 0.8 of going in the desired action direction\n",
    "        self.goInDirection=params[\"goInDirection\"]\n",
    "        self.goOrthogonal=(1-self.goInDirection)/2\n",
    "        # it incurs a livingCost for every non terminal state\n",
    "        self.livingCost=params[\"livingCost\"]\n",
    "\n",
    "    def step(self,action):\n",
    "        # stochasticity in the walk.\n",
    "        # sample from uniform (0,1) distribution using random.random()\n",
    "        random_num=np.random.random()\n",
    "        if random_num<=self.goInDirection:\n",
    "            pass\n",
    "        else:\n",
    "            bernouli_sample = np.random.binomial(1, .5)\n",
    "            if bernouli_sample == 0:\n",
    "                action= (action - 1)%4\n",
    "            else:\n",
    "                action= (action + 1)%4\n",
    "        # left action 0\n",
    "        if action == 0 :\n",
    "            if self.state not in [0,4,8,6, 3,7,5]:\n",
    "                self.state-=1\n",
    "            else:\n",
    "                self.state=self.state\n",
    "        # right action 2\n",
    "        if action == 2 :\n",
    "            if self.state not in [4,11, 3,7,5]:\n",
    "                self.state+=1\n",
    "            else:\n",
    "                self.state=self.state\n",
    "        # up action =1\n",
    "        if action == 1 :\n",
    "            if self.state not in [0,1,2,9, 3,7,5]:\n",
    "                self.state-=4\n",
    "            else:\n",
    "                self.state=self.state\n",
    "        # down action = 3\n",
    "        if action == 3 :\n",
    "            if self.state not in [1,8,9,10,11 ,3,7,5]:\n",
    "                self.state+=4\n",
    "            else:\n",
    "                self.state=self.state\n",
    "\n",
    "        if self.state==3:\n",
    "            reward = 1\n",
    "        elif self.state == 7:\n",
    "            reward = -1\n",
    "        else:\n",
    "            reward=-self.livingCost\n",
    "        # check wether we reached a terminal state or not\n",
    "        if self.state==3 or self.state==7:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        # set placeholder for information\n",
    "        info={}\n",
    "        truncated = False\n",
    "        assert self.state in range(12), \"Hey check your step\"\n",
    "        return self.state,reward,done,truncated,info\n",
    "\n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "    def currState(self):\n",
    "        return self.state\n",
    "\n",
    "    def  reset(self, seed=None, options=None):\n",
    "        # reset state\n",
    "        super().reset(seed=seed)\n",
    "        self.state=self.startState\n",
    "        done=False\n",
    "        info = {}\n",
    "        return self.state,info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gV_cInMvlYVe",
    "outputId": "f8f16817-ecd4-4b53-df1e-96cb4a589149"
   },
   "outputs": [],
   "source": [
    "register(id='RME-v0', entry_point=RandomMaze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DtpFGV0mlYVf"
   },
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "np.random.seed(10)\n",
    "params={}\n",
    "params[\"gamma\"]=0.99\n",
    "params[\"goInDirection\"]=0.8\n",
    "params[\"livingCost\"]=0.04\n",
    "params[\"startState\"]=8\n",
    "params[\"theta\"]=pow(10,-4)\n",
    "params[\"S+\"]=[0,1,2,3,4,6,7,8,9,10,11]\n",
    "params[\"S\"]=[0,1,2,4,6,8,9,10,11]\n",
    "params[\"A\"]=[0,1,2,3]\n",
    "gamma=params[\"gamma\"]\n",
    "env=gym.make('RME-v0',params=params)\n",
    "env.reset(seed=10)\n",
    "done= False\n",
    "noEpisodes=500\n",
    "n=3\n",
    "lamda=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "26kWrV2dlYVg"
   },
   "outputs": [],
   "source": [
    "pi=np.zeros(12)\n",
    "pi[0]=2\n",
    "pi[1]=2\n",
    "pi[2]=2\n",
    "pi[3]=0 #taken any random number\n",
    "pi[4]=1\n",
    "pi[5]=0 #taken any random number\n",
    "pi[6]=1\n",
    "pi[7]=0 #taken any random number\n",
    "pi[8]=1\n",
    "pi[9]=2\n",
    "pi[10]=1\n",
    "pi[11]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AZjrmUJHlYVg",
    "outputId": "6113bd1a-b473-4074-f1f1-81200a5a4d0f"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Generates sample trajectories to be used for learning the value function.\n",
    "Returns list of state,action,next_state,reward tuples.\n",
    "'''\n",
    "\n",
    "def generateTrajectory(env, policy,maxSteps):\n",
    "\n",
    "    list_exp_tuples=[]\n",
    "    done=False\n",
    "    for i in range (maxSteps):\n",
    "        exp_tuples = np.zeros((4))\n",
    "        exp_tuples[0]=env.currState()\n",
    "        exp_tuples[1]=policy[env.currState()]\n",
    "        end_state, reward, done,truncated,info=env.step(policy[env.currState()])\n",
    "        exp_tuples[2]=end_state\n",
    "        exp_tuples[3]=reward\n",
    "        # print(done)\n",
    "        list_exp_tuples.append(exp_tuples)\n",
    "        if done==True:\n",
    "            break\n",
    "    if done==False:\n",
    "        list_exp_tuples=[]\n",
    "    return np.array(list_exp_tuples)\n",
    "np.random.seed(12)\n",
    "random.seed(12)\n",
    "env.reset(seed=12)\n",
    "print(generateTrajectory(env,pi,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "JVugdOZWlYVi",
    "outputId": "3085548e-e1c0-42a4-b1d6-da84c10227e8"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Calculates a decayed Î± value for each timestep.\n",
    "'''\n",
    "def decayAlpha(initialValue, finalValue, maxSteps, decayType):\n",
    "    step_size=np.zeros(maxSteps)\n",
    "    if decayType==\"Linear\":\n",
    "        decayRate=(initialValue-finalValue)/(maxSteps -1)\n",
    "        for i in range(maxSteps):\n",
    "            step_size[i]=initialValue-i*decayRate\n",
    "        # plt.plot(np.arange(0,maxSteps),step_size, color='r')\n",
    "        # plt.ylabel('Step_size Parameter w.r.t time')\n",
    "        # plt.xlabel('Timesteps')\n",
    "        # plt.title('Linear Decay of step size parameter')\n",
    "        # plt.savefig('Linear Decay of step size parameter.pdf')\n",
    "        # plt.close()\n",
    "    if decayType==\"Exp\":\n",
    "        decayRate=(np.log(initialValue/finalValue))/maxSteps\n",
    "        step_size[0]=initialValue\n",
    "        for i in range(maxSteps-1):\n",
    "            step_size[i+1]=step_size[i]*np.exp(-decayRate)\n",
    "        # plt.plot(np.arange(0,maxSteps),step_size, color='r')\n",
    "        # plt.ylabel('Step_size Parameter w.r.t time')\n",
    "        # plt.xlabel('Timesteps')\n",
    "        # plt.title('Exponential Decay of step size parameter')\n",
    "        # plt.savefig('Exponential Decay of step size parameter.pdf')\n",
    "        # plt.close()\n",
    "    return step_size\n",
    "lin_x=decayAlpha(0.5,0.01,250,\"Linear\")\n",
    "exp_x=decayAlpha(0.5,0.01,250,\"Exp\")\n",
    "plt.plot(lin_x,np.arange(250),color='red',linestyle='-')\n",
    "plt.plot(exp_x,np.arange(250),color='blue',linestyle='--')\n",
    "plt.xlabel('Timesteps')\n",
    "plt.ylabel('Step Size Value')\n",
    "plt.title('Strategies for decaying Step Size parameter')\n",
    "plt.savefig('Decay Step Size.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iKvgS67wlYVj"
   },
   "outputs": [],
   "source": [
    "alpha=(decayAlpha(0.5,0.01,250,\"Exp\"))\n",
    "for i in range(250):\n",
    "    alpha = np.append(alpha,0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NX8KywIXlYVj"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "env: The environment object.\n",
    "policy: Policy to follow.\n",
    "gamma: Discount factor.\n",
    "alpha: Array of learning rates.\n",
    "maxSteps: Max steps to simulate.\n",
    "noEpisodes: Number of episodes to run.\n",
    "firstVisit: Boolean to choose between FVMC and EVMC.\n",
    "v: Final value function estimate.\n",
    "v_r: Value function estimate at each episode.\n",
    "Gt: Returns for a particular episode Xnot stateX .\n",
    "'''\n",
    "\n",
    "\n",
    "#state,action,next_state,reward\n",
    "\n",
    "def MonteCarloPrediction(env, policy, gamma, alpha, maxSteps, noEpisodes, firstVisit):\n",
    "    v=np.zeros(env.observation_space.n)\n",
    "    v_r=np.zeros((noEpisodes,env.observation_space.n))\n",
    "    Gt=np.zeros(noEpisodes)\n",
    "    for e in range(noEpisodes):\n",
    "        env.reset(seed=10)\n",
    "        t=generateTrajectory(env, policy,maxSteps)\n",
    "        vis=np.zeros(env.observation_space.n)\n",
    "        for i in range(len(t)):\n",
    "            s=t[i][0]\n",
    "            if vis[int(s)] and firstVisit:\n",
    "                continue\n",
    "            G=0\n",
    "            for j in range(i,len(t)):\n",
    "                G+=(pow(gamma,j-i)*t[j,3])\n",
    "            if s==4:\n",
    "                Gt[e]=G\n",
    "            v[int(s)]=v[int(s)]+alpha[int(e)]*(G-v[int(s)])\n",
    "            vis[int(s)]=1\n",
    "\n",
    "        v_r[e]=v\n",
    "    return v, v_r,Gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v,v_r,Gt = MonteCarloPrediction(env, pi, gamma , alpha, 1000, 500, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YOgp2FdLlYVj"
   },
   "outputs": [],
   "source": [
    "def TemporalDifferencePrediction(env, policy, gamma , alpha, noEpisodes):\n",
    "    v = np.zeros(env.observation_space.n)\n",
    "    v_r = np.zeros((noEpisodes,env.observation_space.n))\n",
    "    Gt=np.zeros(noEpisodes)\n",
    "    for e in range(noEpisodes):\n",
    "        s,done = env.reset(seed=10)\n",
    "        while not done:\n",
    "            action=policy[s]\n",
    "            next_state,reward,done,truncated,info = env.step(action)\n",
    "            td_target = reward\n",
    "            if not done:\n",
    "                td_target = td_target + gamma*v[next_state]\n",
    "            if s==4:\n",
    "                Gt[e]=td_target\n",
    "            td_error = td_target-v[s]\n",
    "            v[s] = v[s] + alpha[e]*td_error\n",
    "            s = next_state\n",
    "        v_r[e] = v\n",
    "    return v,v_r,Gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z5Ezfea_NikQ"
   },
   "outputs": [],
   "source": [
    "v,v_r,Gt = TemporalDifferencePrediction(env, pi, gamma , alpha, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LcW0-EgblYVk"
   },
   "outputs": [],
   "source": [
    "def generateNStepTrajectory(env, policy,n):\n",
    "\n",
    "    list_exp_tuples=[]\n",
    "    done=False\n",
    "    for i in range (n):\n",
    "        exp_tuples = np.zeros((4))\n",
    "        exp_tuples[0]=env.currState()\n",
    "        exp_tuples[1]=policy[env.currState()]\n",
    "        end_state, reward,done,truncated, info=env.step(policy[env.currState()])\n",
    "        #self.state,reward,done,truncated,info\n",
    "        exp_tuples[2]=end_state\n",
    "        exp_tuples[3]=reward\n",
    "        # print(exp_tuples[0])\n",
    "        # print(exp_tuples[1])\n",
    "        # print(exp_tuples[2])\n",
    "        # print(done)\n",
    "        list_exp_tuples.append(exp_tuples)\n",
    "        if done==True:\n",
    "            break\n",
    "    return np.array(list_exp_tuples),env.currState(),done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uel_AdI0lYVk"
   },
   "outputs": [],
   "source": [
    "def calculateReturn(gamma,path):\n",
    "    g_partial=0\n",
    "    for i in range(len(path)):\n",
    "        g_partial+=(path[i][3]*pow(gamma,i))\n",
    "    return g_partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dWIpVHVMlYVl"
   },
   "outputs": [],
   "source": [
    "def nStepTD(env,pi,gamma,alpha,n,noEpisodes):\n",
    "    v = np.zeros(env.observation_space.n)\n",
    "    v_r = np.zeros((noEpisodes,env.observation_space.n))\n",
    "    for e in range (noEpisodes): #noEpisodes\n",
    "        #print(e)\n",
    "        s,done=env.reset()\n",
    "        path=[]\n",
    "        itr = 0\n",
    "        while not done:\n",
    "            path,s_next,done=generateNStepTrajectory(env,pi,n)\n",
    "            #print(path)\n",
    "            #print(\"******\")\n",
    "            target=calculateReturn(gamma,path)\n",
    "            if not done:\n",
    "                target+=pow(gamma,n)*v[s_next]\n",
    "            ntd_error=target-v[s]\n",
    "            v[s]=v[s]+alpha[e]*ntd_error\n",
    "            # if len(path)==1 and done:\n",
    "            #     path = None\n",
    "            s=s_next\n",
    "        v_r[e]=v\n",
    "    return v,v_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gK5P6VyAM6lu",
    "outputId": "5fec48fd-558e-4e5c-dafd-b67fc62fe752"
   },
   "outputs": [],
   "source": [
    "v, v_r = nStepTD(env,pi,gamma,alpha,3,500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YxPMGM8-DDty"
   },
   "outputs": [],
   "source": [
    "def TDlambda(env, pi, gamma, alpha,lam, noEpisodes, params):\n",
    "    v = np.zeros(env.observation_space.n)\n",
    "    v_r = np.zeros((noEpisodes,env.observation_space.n))\n",
    "    eligibility_records = {}\n",
    "    for e in range(noEpisodes):\n",
    "        eligibility_records_for_episode = []\n",
    "        s,done = env.reset(seed=10)\n",
    "        elig = np.zeros(env.observation_space.n) #eligibility vector\n",
    "        while not done:\n",
    "            action=pi[s]\n",
    "            next_state,reward,done,truncated,info = env.step(action)\n",
    "            td_target = reward\n",
    "            if not done:\n",
    "                td_target = td_target + gamma*v[next_state]\n",
    "            td_error = td_target-v[s]\n",
    "            elig[s]+=1\n",
    "            for states in params[\"S\"]:\n",
    "                v[states] = v[states] + alpha[e]*td_error*elig[states]\n",
    "                elig[states] = gamma*lam*elig[states]\n",
    "            s = next_state\n",
    "            eligibility_records_for_episode.append(elig.tolist())\n",
    "        eligibility_records[e] = eligibility_records_for_episode\n",
    "        v_r[e] = v\n",
    "    return v,v_r, eligibility_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqXEB9juF_69",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "value,value_record, eligibility = TDlambda(env, pi, gamma, alpha, 0.2, 500, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True Values:\n",
    "\n",
    "> State 0 - 5/6\n",
    "> \n",
    "> State 1 - 4/6\n",
    "> \n",
    "> State 2 - 3/6\n",
    "> \n",
    "> State 4 - 2/6\n",
    "> \n",
    "> State 6 - 1/6\n",
    "> \n",
    "> State 8 - 1/6\n",
    "> \n",
    "> State 9 - 1/6\n",
    "> \n",
    "> State 10 - 1/6\n",
    "> \n",
    "> State 11 - 1/6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "RDB62uo7lYVl",
    "outputId": "ebf40520-4a77-43d9-9f60-4395f72d5641"
   },
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "np.random.seed(10)\n",
    "v,v_r2 ,Gt= MonteCarloPrediction(env, pi, gamma, alpha, 1000, 500, 1)\n",
    "x = np.arange(0,500)\n",
    "o=np.ones(500)\n",
    "\n",
    "f = plt.figure()\n",
    "f.set_figwidth(20)\n",
    "f.set_figheight(10)\n",
    "\n",
    "plt.plot(x,v_r2[:,0],color = 'blue', label=\"State 0\")\n",
    "plt.plot(x,5/6*o,color = 'blue',linestyle = \"--\", label=\"State 0 True\")\n",
    "plt.plot(x,v_r2[:,1],color = 'green', label=\"State 1\")\n",
    "plt.plot(x,4/6*o,color = 'green',linestyle = \"--\", label=\"State 1 True\")\n",
    "plt.plot(x,v_r2[:,2],color = 'pink', label=\"State 2\")\n",
    "plt.plot(x,3/6*o,color = 'pink',linestyle = \"--\", label=\"State 2 True\")\n",
    "plt.plot(x,v_r2[:,4],color = 'red', label=\"State 4\")\n",
    "plt.plot(x,2/6*o,color = 'red',linestyle = \"--\", label=\"State 4 True\")\n",
    "plt.plot(x,v_r2[:,6],color = 'orange', label=\"State 6\")\n",
    "plt.plot(x,1/6*o,color = 'orange',linestyle = \"--\", label=\"State 6 True\")\n",
    "plt.plot(x,v_r2[:,8],color = 'teal', label=\"State 8\")\n",
    "plt.plot(x,1/6*o,color = 'teal',linestyle = \"--\", label=\"State 8 True\")\n",
    "plt.plot(x,v_r2[:,9],color = 'lime', label=\"State 9\")\n",
    "plt.plot(x,1/6*o,color = 'lime',linestyle = \"--\", label=\"State 9 True\")\n",
    "plt.plot(x,v_r2[:,10],color = 'navy', label=\"State 10\")\n",
    "plt.plot(x,1/6*o,color = 'navy',linestyle = \"--\", label=\"State 10 True\")\n",
    "plt.plot(x,v_r2[:,11],color = 'purple', label=\"State 11\")\n",
    "plt.plot(x,1/6*o,color = 'purple',linestyle = \"--\", label=\"State 11 True\")\n",
    "plt.legend()\n",
    "\n",
    "plt.title(\"FVMC estimates through time vs. true values\")\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"State-Value Function\")\n",
    "plt.savefig(\"problem 3, Q-8.pdf\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "np.random.seed(10)\n",
    "v,v_r2 ,Gt= MonteCarloPrediction(env, pi, gamma, alpha, 1000, 500, 0)\n",
    "x = np.arange(0,500)\n",
    "o=np.ones(500)\n",
    "\n",
    "f = plt.figure()\n",
    "f.set_figwidth(20)\n",
    "f.set_figheight(10)\n",
    "\n",
    "plt.plot(x,v_r2[:,0],color = 'blue', label=\"State 0\")\n",
    "plt.plot(x,5/6*o,color = 'blue',linestyle = \"--\", label=\"State 0 True\")\n",
    "plt.plot(x,v_r2[:,1],color = 'green', label=\"State 1\")\n",
    "plt.plot(x,4/6*o,color = 'green',linestyle = \"--\", label=\"State 1 True\")\n",
    "plt.plot(x,v_r2[:,2],color = 'pink', label=\"State 2\")\n",
    "plt.plot(x,3/6*o,color = 'pink',linestyle = \"--\", label=\"State 2 True\")\n",
    "plt.plot(x,v_r2[:,4],color = 'red', label=\"State 4\")\n",
    "plt.plot(x,2/6*o,color = 'red',linestyle = \"--\", label=\"State 4 True\")\n",
    "plt.plot(x,v_r2[:,6],color = 'orange', label=\"State 6\")\n",
    "plt.plot(x,1/6*o,color = 'orange',linestyle = \"--\", label=\"State 6 True\")\n",
    "plt.plot(x,v_r2[:,8],color = 'teal', label=\"State 8\")\n",
    "plt.plot(x,1/6*o,color = 'teal',linestyle = \"--\", label=\"State 8 True\")\n",
    "plt.plot(x,v_r2[:,9],color = 'lime', label=\"State 9\")\n",
    "plt.plot(x,1/6*o,color = 'lime',linestyle = \"--\", label=\"State 9 True\")\n",
    "plt.plot(x,v_r2[:,10],color = 'navy', label=\"State 10\")\n",
    "plt.plot(x,1/6*o,color = 'navy',linestyle = \"--\", label=\"State 10 True\")\n",
    "plt.plot(x,v_r2[:,11],color = 'purple', label=\"State 11\")\n",
    "plt.plot(x,1/6*o,color = 'purple',linestyle = \"--\", label=\"State 11 True\")\n",
    "plt.legend()\n",
    "\n",
    "plt.title(\"EVMC estimates through time vs. true values\")\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"State-Value Function\")\n",
    "# plt.legend([\"V(1)\", \"V(\",\"pink\",\"red\",\"orange\"])\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1.0, 0.3, 0.2), loc='upper left')\n",
    "plt.savefig(\"problem 3, Q-9.pdf\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "np.random.seed(10)\n",
    "v,v_r2 ,Gt= TemporalDifferencePrediction(env, pi, gamma, alpha, 500)\n",
    "x = np.arange(0,500)\n",
    "o=np.ones(500)\n",
    "\n",
    "f = plt.figure()\n",
    "f.set_figwidth(20)\n",
    "f.set_figheight(10)\n",
    "\n",
    "plt.plot(x,v_r2[:,0],color = 'blue', label=\"State 0\")\n",
    "plt.plot(x,5/6*o,color = 'blue',linestyle = \"--\", label=\"State 0 True\")\n",
    "plt.plot(x,v_r2[:,1],color = 'green', label=\"State 1\")\n",
    "plt.plot(x,4/6*o,color = 'green',linestyle = \"--\", label=\"State 1 True\")\n",
    "plt.plot(x,v_r2[:,2],color = 'pink', label=\"State 2\")\n",
    "plt.plot(x,3/6*o,color = 'pink',linestyle = \"--\", label=\"State 2 True\")\n",
    "plt.plot(x,v_r2[:,4],color = 'red', label=\"State 4\")\n",
    "plt.plot(x,2/6*o,color = 'red',linestyle = \"--\", label=\"State 4 True\")\n",
    "plt.plot(x,v_r2[:,6],color = 'orange', label=\"State 6\")\n",
    "plt.plot(x,1/6*o,color = 'orange',linestyle = \"--\", label=\"State 6 True\")\n",
    "plt.plot(x,v_r2[:,8],color = 'teal', label=\"State 8\")\n",
    "plt.plot(x,1/6*o,color = 'teal',linestyle = \"--\", label=\"State 8 True\")\n",
    "plt.plot(x,v_r2[:,9],color = 'lime', label=\"State 9\")\n",
    "plt.plot(x,1/6*o,color = 'lime',linestyle = \"--\", label=\"State 9 True\")\n",
    "plt.plot(x,v_r2[:,10],color = 'navy', label=\"State 10\")\n",
    "plt.plot(x,1/6*o,color = 'navy',linestyle = \"--\", label=\"State 10 True\")\n",
    "plt.plot(x,v_r2[:,11],color = 'purple', label=\"State 11\")\n",
    "plt.plot(x,1/6*o,color = 'purple',linestyle = \"--\", label=\"State 11 True\")\n",
    "plt.legend()\n",
    "\n",
    "plt.title(\"TD estimates through time vs. true values\")\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"State-Value Function\")\n",
    "# plt.legend([\"V(1)\", \"V(\",\"pink\",\"red\",\"orange\"])\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1.0, 0.3, 0.2), loc='upper left')\n",
    "plt.savefig(\"problem 3, Q-10.pdf\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "np.random.seed(10)\n",
    "v,v_r2 = nStepTD(env,pi,gamma,alpha,3,500)\n",
    "x = np.arange(0,500)\n",
    "o=np.ones(500)\n",
    "\n",
    "f = plt.figure()\n",
    "f.set_figwidth(20)\n",
    "f.set_figheight(10)\n",
    "\n",
    "plt.plot(x,v_r2[:,0],color = 'blue', label=\"State 0\")\n",
    "plt.plot(x,5/6*o,color = 'blue',linestyle = \"--\", label=\"State 0 True\")\n",
    "plt.plot(x,v_r2[:,1],color = 'green', label=\"State 1\")\n",
    "plt.plot(x,4/6*o,color = 'green',linestyle = \"--\", label=\"State 1 True\")\n",
    "plt.plot(x,v_r2[:,2],color = 'pink', label=\"State 2\")\n",
    "plt.plot(x,3/6*o,color = 'pink',linestyle = \"--\", label=\"State 2 True\")\n",
    "plt.plot(x,v_r2[:,4],color = 'red', label=\"State 4\")\n",
    "plt.plot(x,2/6*o,color = 'red',linestyle = \"--\", label=\"State 4 True\")\n",
    "plt.plot(x,v_r2[:,6],color = 'orange', label=\"State 6\")\n",
    "plt.plot(x,1/6*o,color = 'orange',linestyle = \"--\", label=\"State 6 True\")\n",
    "plt.plot(x,v_r2[:,8],color = 'teal', label=\"State 8\")\n",
    "plt.plot(x,1/6*o,color = 'teal',linestyle = \"--\", label=\"State 8 True\")\n",
    "plt.plot(x,v_r2[:,9],color = 'lime', label=\"State 9\")\n",
    "plt.plot(x,1/6*o,color = 'lime',linestyle = \"--\", label=\"State 9 True\")\n",
    "plt.plot(x,v_r2[:,10],color = 'navy', label=\"State 10\")\n",
    "plt.plot(x,1/6*o,color = 'navy',linestyle = \"--\", label=\"State 10 True\")\n",
    "plt.plot(x,v_r2[:,11],color = 'purple', label=\"State 11\")\n",
    "plt.plot(x,1/6*o,color = 'purple',linestyle = \"--\", label=\"State 11 True\")\n",
    "plt.legend()\n",
    "\n",
    "plt.title(\"n-Step TD estimates through time vs. true values\")\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"State-Value Function\")\n",
    "# plt.legend([\"V(1)\", \"V(\",\"pink\",\"red\",\"orange\"])\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1.0, 0.3, 0.2), loc='upper left')\n",
    "plt.savefig(\"problem 3, Q-11.pdf\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "np.random.seed(10)\n",
    "v,v_r2, _ = TDlambda(env, pi, gamma, alpha, 0.3, 500, params)\n",
    "x = np.arange(0,500)\n",
    "o=np.ones(500)\n",
    "\n",
    "\n",
    "f = plt.figure()\n",
    "f.set_figwidth(20)\n",
    "f.set_figheight(10)\n",
    "\n",
    "plt.plot(x,v_r2[:,0],color = 'blue', label=\"State 0\")\n",
    "plt.plot(x,5/6*o,color = 'blue',linestyle = \"--\", label=\"State 0 True\")\n",
    "plt.plot(x,v_r2[:,1],color = 'green', label=\"State 1\")\n",
    "plt.plot(x,4/6*o,color = 'green',linestyle = \"--\", label=\"State 1 True\")\n",
    "plt.plot(x,v_r2[:,2],color = 'pink', label=\"State 2\")\n",
    "plt.plot(x,3/6*o,color = 'pink',linestyle = \"--\", label=\"State 2 True\")\n",
    "plt.plot(x,v_r2[:,4],color = 'red', label=\"State 4\")\n",
    "plt.plot(x,2/6*o,color = 'red',linestyle = \"--\", label=\"State 4 True\")\n",
    "plt.plot(x,v_r2[:,6],color = 'orange', label=\"State 6\")\n",
    "plt.plot(x,1/6*o,color = 'orange',linestyle = \"--\", label=\"State 6 True\")\n",
    "plt.plot(x,v_r2[:,8],color = 'teal', label=\"State 8\")\n",
    "plt.plot(x,1/6*o,color = 'teal',linestyle = \"--\", label=\"State 8 True\")\n",
    "plt.plot(x,v_r2[:,9],color = 'lime', label=\"State 9\")\n",
    "plt.plot(x,1/6*o,color = 'lime',linestyle = \"--\", label=\"State 9 True\")\n",
    "plt.plot(x,v_r2[:,10],color = 'navy', label=\"State 10\")\n",
    "plt.plot(x,1/6*o,color = 'navy',linestyle = \"--\", label=\"State 10 True\")\n",
    "plt.plot(x,v_r2[:,11],color = 'purple', label=\"State 11\")\n",
    "plt.plot(x,1/6*o,color = 'purple',linestyle = \"--\", label=\"State 11 True\")\n",
    "plt.legend()\n",
    "\n",
    "plt.title(\"TD(lambda) estimates through time vs. true values\")\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"State-Value Function\")\n",
    "# plt.legend([\"V(1)\", \"V(\",\"pink\",\"red\",\"orange\"])\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1.0, 0.3, 0.2), loc='upper left')\n",
    "plt.savefig(\"problem 3, Q-12.pdf\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "np.random.seed(10)\n",
    "v,v_r2, eligibility = TDlambda(env, pi, gamma, alpha, 0.3, 500, params)\n",
    "episode_100_eligibility_records = np.array(eligibility[100])\n",
    "x = np.arange(0,episode_100_eligibility_records.shape[0])\n",
    "\n",
    "f = plt.figure()\n",
    "f.set_figwidth(20)\n",
    "f.set_figheight(10)\n",
    "\n",
    "plt.plot(x,episode_100_eligibility_records[:,0],color = 'blue', label=\"State 0\")\n",
    "plt.plot(x,episode_100_eligibility_records[:,1],color = 'green', label=\"State 1\")\n",
    "plt.plot(x,episode_100_eligibility_records[:,2],color = 'pink', label=\"State 2\")\n",
    "plt.plot(x,episode_100_eligibility_records[:,4],color = 'red', label=\"State 4\")\n",
    "plt.plot(x,episode_100_eligibility_records[:,6],color = 'orange', label=\"State 6\")\n",
    "plt.plot(x,episode_100_eligibility_records[:,8],color = 'teal', label=\"State 8\")\n",
    "plt.plot(x,episode_100_eligibility_records[:,9],color = 'lime', label=\"State 9\")\n",
    "plt.plot(x,episode_100_eligibility_records[:,10],color = 'navy', label=\"State 10\")\n",
    "plt.plot(x,episode_100_eligibility_records[:,11],color = 'purple', label=\"State 11\")\n",
    "plt.title(\"n-Step TD Eligibility trace through time [Episode 100]\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Eligibility\")\n",
    "plt.legend()\n",
    "plt.savefig(\"problem 3, Q-13.pdf\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "np.random.seed(10)\n",
    "v,v_r2 ,Gt= MonteCarloPrediction(env, pi, gamma, alpha, 1000, 500, 1)\n",
    "x = np.arange(0,500)\n",
    "o=np.ones(500)\n",
    "\n",
    "f = plt.figure()\n",
    "f.set_figwidth(20)\n",
    "f.set_figheight(10)\n",
    "\n",
    "plt.plot(x,v_r2[:,0],color = 'blue', label=\"State 0\")\n",
    "plt.plot(x,5/6*o,color = 'blue',linestyle = \"--\", label=\"State 0 True\")\n",
    "plt.plot(x,v_r2[:,1],color = 'green', label=\"State 1\")\n",
    "plt.plot(x,4/6*o,color = 'green',linestyle = \"--\", label=\"State 1 True\")\n",
    "plt.plot(x,v_r2[:,2],color = 'pink', label=\"State 2\")\n",
    "plt.plot(x,3/6*o,color = 'pink',linestyle = \"--\", label=\"State 2 True\")\n",
    "plt.plot(x,v_r2[:,4],color = 'red', label=\"State 4\")\n",
    "plt.plot(x,2/6*o,color = 'red',linestyle = \"--\", label=\"State 4 True\")\n",
    "plt.plot(x,v_r2[:,6],color = 'orange', label=\"State 6\")\n",
    "plt.plot(x,1/6*o,color = 'orange',linestyle = \"--\", label=\"State 6 True\")\n",
    "plt.plot(x,v_r2[:,8],color = 'teal', label=\"State 8\")\n",
    "plt.plot(x,1/6*o,color = 'teal',linestyle = \"--\", label=\"State 8 True\")\n",
    "plt.plot(x,v_r2[:,9],color = 'lime', label=\"State 9\")\n",
    "plt.plot(x,1/6*o,color = 'lime',linestyle = \"--\", label=\"State 9 True\")\n",
    "plt.plot(x,v_r2[:,10],color = 'navy', label=\"State 10\")\n",
    "plt.plot(x,1/6*o,color = 'navy',linestyle = \"--\", label=\"State 10 True\")\n",
    "plt.plot(x,v_r2[:,11],color = 'purple', label=\"State 11\")\n",
    "plt.plot(x,1/6*o,color = 'purple',linestyle = \"--\", label=\"State 11 True\")\n",
    "plt.legend()\n",
    "\n",
    "plt.title(\"FVMC estimates through time [logscale] vs. true values\")\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"State-Value Function\")\n",
    "plt.xscale('log')\n",
    "# plt.legend([\"V(1)\", \"V(\",\"pink\",\"red\",\"orange\"])\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1.0, 0.3, 0.2), loc='upper left')\n",
    "plt.savefig(\"problem 3, Q-14.pdf\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "np.random.seed(10)\n",
    "v,v_r2 ,Gt= MonteCarloPrediction(env, pi, gamma, alpha, 1000, 500, 0)\n",
    "x = np.arange(0,500)\n",
    "o=np.ones(500)\n",
    "\n",
    "f = plt.figure()\n",
    "f.set_figwidth(20)\n",
    "f.set_figheight(10)\n",
    "\n",
    "plt.plot(x,v_r2[:,0],color = 'blue', label=\"State 0\")\n",
    "plt.plot(x,5/6*o,color = 'blue',linestyle = \"--\", label=\"State 0 True\")\n",
    "plt.plot(x,v_r2[:,1],color = 'green', label=\"State 1\")\n",
    "plt.plot(x,4/6*o,color = 'green',linestyle = \"--\", label=\"State 1 True\")\n",
    "plt.plot(x,v_r2[:,2],color = 'pink', label=\"State 2\")\n",
    "plt.plot(x,3/6*o,color = 'pink',linestyle = \"--\", label=\"State 2 True\")\n",
    "plt.plot(x,v_r2[:,4],color = 'red', label=\"State 4\")\n",
    "plt.plot(x,2/6*o,color = 'red',linestyle = \"--\", label=\"State 4 True\")\n",
    "plt.plot(x,v_r2[:,6],color = 'orange', label=\"State 6\")\n",
    "plt.plot(x,1/6*o,color = 'orange',linestyle = \"--\", label=\"State 6 True\")\n",
    "plt.plot(x,v_r2[:,8],color = 'teal', label=\"State 8\")\n",
    "plt.plot(x,1/6*o,color = 'teal',linestyle = \"--\", label=\"State 8 True\")\n",
    "plt.plot(x,v_r2[:,9],color = 'lime', label=\"State 9\")\n",
    "plt.plot(x,1/6*o,color = 'lime',linestyle = \"--\", label=\"State 9 True\")\n",
    "plt.plot(x,v_r2[:,10],color = 'navy', label=\"State 10\")\n",
    "plt.plot(x,1/6*o,color = 'navy',linestyle = \"--\", label=\"State 10 True\")\n",
    "plt.plot(x,v_r2[:,11],color = 'purple', label=\"State 11\")\n",
    "plt.plot(x,1/6*o,color = 'purple',linestyle = \"--\", label=\"State 11 True\")\n",
    "plt.legend()\n",
    "\n",
    "plt.title(\"EVMC estimates through time [logscale] vs. true values\")\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"State-Value Function\")\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.savefig(\"problem 3, Q-15.pdf\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "np.random.seed(10)\n",
    "v,v_r2 ,Gt= TemporalDifferencePrediction(env, pi, gamma, alpha, 500)\n",
    "x = np.arange(0,500)\n",
    "o=np.ones(500)\n",
    "\n",
    "f = plt.figure()\n",
    "f.set_figwidth(20)\n",
    "f.set_figheight(10)\n",
    "\n",
    "plt.plot(x,v_r2[:,0],color = 'blue', label=\"State 0\")\n",
    "plt.plot(x,5/6*o,color = 'blue',linestyle = \"--\", label=\"State 0 True\")\n",
    "plt.plot(x,v_r2[:,1],color = 'green', label=\"State 1\")\n",
    "plt.plot(x,4/6*o,color = 'green',linestyle = \"--\", label=\"State 1 True\")\n",
    "plt.plot(x,v_r2[:,2],color = 'pink', label=\"State 2\")\n",
    "plt.plot(x,3/6*o,color = 'pink',linestyle = \"--\", label=\"State 2 True\")\n",
    "plt.plot(x,v_r2[:,4],color = 'red', label=\"State 4\")\n",
    "plt.plot(x,2/6*o,color = 'red',linestyle = \"--\", label=\"State 4 True\")\n",
    "plt.plot(x,v_r2[:,6],color = 'orange', label=\"State 6\")\n",
    "plt.plot(x,1/6*o,color = 'orange',linestyle = \"--\", label=\"State 6 True\")\n",
    "plt.plot(x,v_r2[:,8],color = 'teal', label=\"State 8\")\n",
    "plt.plot(x,1/6*o,color = 'teal',linestyle = \"--\", label=\"State 8 True\")\n",
    "plt.plot(x,v_r2[:,9],color = 'lime', label=\"State 9\")\n",
    "plt.plot(x,1/6*o,color = 'lime',linestyle = \"--\", label=\"State 9 True\")\n",
    "plt.plot(x,v_r2[:,10],color = 'navy', label=\"State 10\")\n",
    "plt.plot(x,1/6*o,color = 'navy',linestyle = \"--\", label=\"State 10 True\")\n",
    "plt.plot(x,v_r2[:,11],color = 'purple', label=\"State 11\")\n",
    "plt.plot(x,1/6*o,color = 'purple',linestyle = \"--\", label=\"State 11 True\")\n",
    "plt.legend()\n",
    "\n",
    "plt.title(\"TD estimates through time [logscale] vs. true values\")\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"State-Value Function\")\n",
    "plt.xscale('log')\n",
    "plt.savefig(\"problem 3, Q-16.pdf\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "np.random.seed(10)\n",
    "v,v_r2 = nStepTD(env,pi,gamma,alpha,3,500)\n",
    "x = np.arange(0,500)\n",
    "o=np.ones(500)\n",
    "\n",
    "f = plt.figure()\n",
    "f.set_figwidth(20)\n",
    "f.set_figheight(10)\n",
    "\n",
    "plt.plot(x,v_r2[:,0],color = 'blue', label=\"State 0\")\n",
    "plt.plot(x,5/6*o,color = 'blue',linestyle = \"--\", label=\"State 0 True\")\n",
    "plt.plot(x,v_r2[:,1],color = 'green', label=\"State 1\")\n",
    "plt.plot(x,4/6*o,color = 'green',linestyle = \"--\", label=\"State 1 True\")\n",
    "plt.plot(x,v_r2[:,2],color = 'pink', label=\"State 2\")\n",
    "plt.plot(x,3/6*o,color = 'pink',linestyle = \"--\", label=\"State 2 True\")\n",
    "plt.plot(x,v_r2[:,4],color = 'red', label=\"State 4\")\n",
    "plt.plot(x,2/6*o,color = 'red',linestyle = \"--\", label=\"State 4 True\")\n",
    "plt.plot(x,v_r2[:,6],color = 'orange', label=\"State 6\")\n",
    "plt.plot(x,1/6*o,color = 'orange',linestyle = \"--\", label=\"State 6 True\")\n",
    "plt.plot(x,v_r2[:,8],color = 'teal', label=\"State 8\")\n",
    "plt.plot(x,1/6*o,color = 'teal',linestyle = \"--\", label=\"State 8 True\")\n",
    "plt.plot(x,v_r2[:,9],color = 'lime', label=\"State 9\")\n",
    "plt.plot(x,1/6*o,color = 'lime',linestyle = \"--\", label=\"State 9 True\")\n",
    "plt.plot(x,v_r2[:,10],color = 'navy', label=\"State 10\")\n",
    "plt.plot(x,1/6*o,color = 'navy',linestyle = \"--\", label=\"State 10 True\")\n",
    "plt.plot(x,v_r2[:,11],color = 'purple', label=\"State 11\")\n",
    "plt.plot(x,1/6*o,color = 'purple',linestyle = \"--\", label=\"State 11 True\")\n",
    "plt.legend()\n",
    "\n",
    "plt.title(\"n-Step TD estimates through time [logscale] vs. true values\")\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"State-Value Function\")\n",
    "plt.xscale('log')\n",
    "plt.savefig(\"problem 3, Q-17.pdf\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "np.random.seed(10)\n",
    "v,v_r2, _ = TDlambda(env, pi, gamma, alpha, 0.3, 500, params)\n",
    "x = np.arange(0,500)\n",
    "o=np.ones(500)\n",
    "\n",
    "f = plt.figure()\n",
    "f.set_figwidth(20)\n",
    "f.set_figheight(10)\n",
    "\n",
    "plt.plot(x,v_r2[:,0],color = 'blue', label=\"State 0\")\n",
    "plt.plot(x,5/6*o,color = 'blue',linestyle = \"--\", label=\"State 0 True\")\n",
    "plt.plot(x,v_r2[:,1],color = 'green', label=\"State 1\")\n",
    "plt.plot(x,4/6*o,color = 'green',linestyle = \"--\", label=\"State 1 True\")\n",
    "plt.plot(x,v_r2[:,2],color = 'pink', label=\"State 2\")\n",
    "plt.plot(x,3/6*o,color = 'pink',linestyle = \"--\", label=\"State 2 True\")\n",
    "plt.plot(x,v_r2[:,4],color = 'red', label=\"State 4\")\n",
    "plt.plot(x,2/6*o,color = 'red',linestyle = \"--\", label=\"State 4 True\")\n",
    "plt.plot(x,v_r2[:,6],color = 'orange', label=\"State 6\")\n",
    "plt.plot(x,1/6*o,color = 'orange',linestyle = \"--\", label=\"State 6 True\")\n",
    "plt.plot(x,v_r2[:,8],color = 'teal', label=\"State 8\")\n",
    "plt.plot(x,1/6*o,color = 'teal',linestyle = \"--\", label=\"State 8 True\")\n",
    "plt.plot(x,v_r2[:,9],color = 'lime', label=\"State 9\")\n",
    "plt.plot(x,1/6*o,color = 'lime',linestyle = \"--\", label=\"State 9 True\")\n",
    "plt.plot(x,v_r2[:,10],color = 'navy', label=\"State 10\")\n",
    "plt.plot(x,1/6*o,color = 'navy',linestyle = \"--\", label=\"State 10 True\")\n",
    "plt.plot(x,v_r2[:,11],color = 'purple', label=\"State 11\")\n",
    "plt.plot(x,1/6*o,color = 'purple',linestyle = \"--\", label=\"State 11 True\")\n",
    "plt.legend()\n",
    "\n",
    "plt.title(\"TD(lambda) estimates through time [logscale] vs. true values\")\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"State-Value Function\")\n",
    "plt.xscale('log')\n",
    "plt.savefig(\"problem 3, Q-18.pdf\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_EPISODE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "np.random.seed(10)\n",
    "x = np.arange(START_EPISODE,500)\n",
    "o=np.ones(500 - START_EPISODE)\n",
    "\n",
    "f = plt.figure()\n",
    "f.set_figwidth(20)\n",
    "f.set_figheight(5)\n",
    "\n",
    "v,v_r2_mf ,Gt= MonteCarloPrediction(env, pi, gamma, alpha, 1000, 500, 1)\n",
    "v,v_r2_me ,Gt= MonteCarloPrediction(env, pi, gamma, alpha, 1000, 500, 0)\n",
    "v,v_r2_td ,Gt= TemporalDifferencePrediction(env, pi, gamma, alpha, 500)\n",
    "v,v_r2_ntd = nStepTD(env,pi,gamma,alpha,3,500)\n",
    "v,v_r2_tdlambda, _ = TDlambda(env, pi, gamma, alpha, 0.3, 500, params)\n",
    "\n",
    "plt.plot(x,v_r2_mf[START_EPISODE:,4],color = 'blue', label=\"EVMC\")\n",
    "plt.plot(x,v_r2_me[START_EPISODE:,4],color = 'red', label=\"FVMC\")\n",
    "plt.plot(x,v_r2_td[START_EPISODE:,4],color = 'green', label=\"TD\")\n",
    "plt.plot(x,v_r2_ntd[START_EPISODE:,4],color = 'orange', label=\"nStep TD\")\n",
    "plt.plot(x,v_r2_tdlambda[START_EPISODE:,4],color = 'black', label=\"TD Lambda\")\n",
    "plt.plot(x,2/6*o,color = 'red',linestyle = \"--\", label=\"True value\")\n",
    "\n",
    "plt.title(f\"Evaluation of various algorithms on State 4 through time from Episodes : {START_EPISODE} to 500\")\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"State-Value Function\")\n",
    "plt.legend()\n",
    "plt.savefig(\"problem 3, Q-19.pdf\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "np.random.seed(10)\n",
    "\n",
    "f = plt.figure()\n",
    "f.set_figwidth(20)\n",
    "f.set_figheight(10)\n",
    "\n",
    "v,v_r2 ,Gt= MonteCarloPrediction(env, pi, gamma, alpha, 1000, 500, 1)\n",
    "x = np.arange(0,Gt.shape[0])\n",
    "plt.scatter(x,Gt,color = 'blue', label=\"Gt values\")\n",
    "plt.plot(x,2/6*o,color = 'red',linestyle = \"--\", label=\"True value\")\n",
    "plt.title(\"FVMC Target Value (Gt) of State 4 through time\")\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Target Value (Gt)\")\n",
    "plt.legend()\n",
    "plt.savefig(\"problem 3, Q-20.pdf\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "np.random.seed(10)\n",
    "\n",
    "f = plt.figure()\n",
    "f.set_figwidth(20)\n",
    "f.set_figheight(10)\n",
    "\n",
    "v,v_r2 ,Gt= MonteCarloPrediction(env, pi, gamma, alpha, 1000, 500, 0)\n",
    "x = np.arange(0,Gt.shape[0])\n",
    "plt.scatter(x,Gt,color = 'blue', label=\"Gt values\")\n",
    "plt.plot(x,2/6*o,color = 'red',linestyle = \"--\", label=\"True value\")\n",
    "\n",
    "plt.title(\"EVMC Target Value (Gt) of State 4 through time\")\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Target Value (Gt)\")\n",
    "plt.savefig(\"problem 3, Q-21.pdf\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "np.random.seed(10)\n",
    "\n",
    "f = plt.figure()\n",
    "f.set_figwidth(20)\n",
    "f.set_figheight(10)\n",
    "\n",
    "v,v_r2 ,Gt= TemporalDifferencePrediction(env, pi, gamma, alpha, 500)\n",
    "x = np.arange(0,500)\n",
    "o=np.ones(500)\n",
    "plt.scatter(x,Gt,color = 'blue', label=\"Gt values\")\n",
    "plt.plot(x,2/6*o,color = 'red',linestyle = \"--\", label=\"True value\")\n",
    "plt.title(\"TD Target Value (Gt) of State 4 through time\")\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Target Value (Gt)\")\n",
    "plt.savefig(\"problem 3, Q-22.pdf\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "interpreter": {
   "hash": "9e8fbf9a983a2b3ad981a2f9c2c427da9bcf0d16346e2ead530ccf2c05c5df6b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
