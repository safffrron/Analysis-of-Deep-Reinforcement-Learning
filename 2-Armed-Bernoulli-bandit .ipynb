{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a891074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all useful functions \n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import gymnasium as gym\n",
    "from gymnasium import Env, spaces, register, make\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5751f481",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BernoulliBandit(Env):\n",
    "    \n",
    "    \n",
    "    #----- 1 -----\n",
    "    #constructor for initialization and some helper functions\n",
    "    \n",
    "    \n",
    "    def __init__(self, render_mode=None, alpha = 1.0 , beta = 1.0):\n",
    "        \n",
    "        #P is basically State: Action: [ Transition Probability , Next state , Reward , isTerminated?]\n",
    "        self.P = {\n",
    "            0: {\n",
    "                0: [(1.0, 0, 0.0, True)],\n",
    "                1: [(1.0, 0, 0.0, True)]\n",
    "            },\n",
    "            1: {\n",
    "                0: [(alpha, 0, 1.0, True), (1-alpha, 2, 0.0, True)],\n",
    "                1: [(beta, 2, 1.0, True), (1-beta, 0, 0.0, True)]\n",
    "            },\n",
    "            2: {\n",
    "                0: [(1.0, 2, 0.0, True)],\n",
    "                1: [(1.0, 2, 0.0, True)]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        self.size = 3 # The size of the 1D grid\n",
    "#         self.window_size = 512  # The size of the PyGame window\n",
    "        \n",
    "        # We have 3 observations, corresponding to each position in the 1-D grid\n",
    "        self.observation_space = spaces.Discrete(self.size)\n",
    "\n",
    "        # We have 2 actions, corresponding to \"left\" & \"right\"\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "        self.action_space_size = 2 \n",
    "        \n",
    "    \n",
    "    #return the locations of agent and target\n",
    "    def _get_obs(self):\n",
    "        return {   \n",
    "            \"agent\" : self._agent_location, \n",
    "            \"target\": self._target_location  \n",
    "        }\n",
    "    \n",
    "    #returns the distance between agent and target \n",
    "    def _get_info(self):\n",
    "        return {  \n",
    "            \"distance\": abs(self._agent_location - self._target_location)   \n",
    "        }\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #----- 2 ------\n",
    "    # The reset function to initiate \n",
    "    \n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        \n",
    "        self._agent_location = 1             #location of agent in the begining\n",
    "        self._target_location = self.size-1  #starting location of target in this case 2 \n",
    "        self._dead_state = 0                 #dead location\n",
    "        \n",
    "        \n",
    "        observation = self._get_obs()        #getting useful information\n",
    "        info = self._get_info()\n",
    "\n",
    "        return observation,info\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #------- 3 ---------\n",
    "    # The step function \n",
    "    \n",
    "    def step(self, action):  # takes action as a parameter\n",
    "\n",
    "        # gets the current location and stores the values from P set \n",
    "        prev_location = self._agent_location                                #gets location\n",
    "        transitions = self.P[prev_location][action]                         #gets the corresponding action tuple\n",
    "        probabilities, next_states, rewards, terminals = zip(*transitions)  #stores the value for use \n",
    "        \n",
    "        # Randomly select a transition based on the probabilities\n",
    "        # gives you random state based on your probabilities \n",
    "        index = random.choices(range(len(probabilities)), weights=probabilities, k=1)[0]\n",
    "        # stores the values \n",
    "        self._agent_location, reward, terminated = next_states[index], rewards[index], terminals[index]\n",
    "        \n",
    "        truncated = False\n",
    "        observation = self._get_obs()  \n",
    "        info = self._get_info()\n",
    "\n",
    "        info[\"log\"] = {\"current_state\": prev_location, \n",
    "                       \"action\":action,  \n",
    "                        \"next_state\": self._agent_location}\n",
    "\n",
    "        # Return the required 5-tuple\n",
    "        return observation, reward, terminated, truncated, info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "906cf9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the custom environment\n",
    "register(id='BBandit', entry_point=BernoulliBandit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cfa0a6c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'current_state': 1, 'action': 0, 'next_state': 2}\n",
      "Terminated \n",
      "\n",
      "{'current_state': 1, 'action': 0, 'next_state': 2}\n",
      "Terminated \n",
      "\n",
      "{'current_state': 1, 'action': 0, 'next_state': 0}\n",
      "Terminated \n",
      "\n",
      "{'current_state': 1, 'action': 1, 'next_state': 2}\n",
      "Terminated \n",
      "\n",
      "{'current_state': 1, 'action': 0, 'next_state': 0}\n",
      "Terminated \n",
      "\n",
      "{'current_state': 1, 'action': 0, 'next_state': 0}\n",
      "Terminated \n",
      "\n",
      "{'current_state': 1, 'action': 1, 'next_state': 2}\n",
      "Terminated \n",
      "\n",
      "{'current_state': 1, 'action': 1, 'next_state': 0}\n",
      "Terminated \n",
      "\n",
      "{'current_state': 1, 'action': 0, 'next_state': 0}\n",
      "Terminated \n",
      "\n",
      "{'current_state': 1, 'action': 1, 'next_state': 2}\n",
      "Terminated \n",
      "\n",
      " Average Reward over 10 episode =  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kislayadityaoj/opt/anaconda3/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:127: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method should be an int or np.int64, actual type: <class 'dict'>\u001b[0m\n",
      "  logger.warn(f\"{pre} should be an int or np.int64, actual type: {type(obs)}\")\n",
      "/Users/kislayadityaoj/opt/anaconda3/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/Users/kislayadityaoj/opt/anaconda3/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:127: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method should be an int or np.int64, actual type: <class 'dict'>\u001b[0m\n",
      "  logger.warn(f\"{pre} should be an int or np.int64, actual type: {type(obs)}\")\n",
      "/Users/kislayadityaoj/opt/anaconda3/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    }
   ],
   "source": [
    "# a=float(input(\"Enter the value of alpha -  \"))\n",
    "# b=float(input(\"Enter the value of beta -  \"))\n",
    "\n",
    "# Create and use the environment\n",
    "environment = make('BBandit', alpha = 0.8 , beta = 0.8)\n",
    "\n",
    "reward_sum = 0\n",
    "observation = environment.reset(seed=0)\n",
    "for _ in range(10):\n",
    "    action = environment.action_space.sample()  # this is where you would insert your policy\n",
    "    observation, reward, terminated, truncated, info = environment.step(action)\n",
    "    reward_sum += reward\n",
    "    print(info['log'])\n",
    "\n",
    "    if terminated:\n",
    "        print(\"Terminated\", \"\\n\")\n",
    "\n",
    "    \n",
    "    if terminated or truncated:\n",
    "        observation = environment.reset(seed=0)\n",
    "        \n",
    "        \n",
    "print(\" Average Reward over 10 episode = \" , int(reward_sum * 0.1))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bab9128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kislayadityaoj/opt/anaconda3/lib/python3.9/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.action_space_size to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.action_space_size` for environment variables or `env.get_wrapper_attr('action_space_size')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  0., 100., 100., 100., 100., 100., 100., 100., 100., 100.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Greedy Stratergy - Pure Exploitation \n",
    "\n",
    "def PureExploitation(Env , maxEpisodes):\n",
    "    \n",
    "    Q = np.zeros(Env.action_space_size)\n",
    "    N = np.zeros(Env.action_space_size)\n",
    "    e=1\n",
    "    Q_est = np.zeros((maxEpisodes,Env.action_space_size))\n",
    "    R_est = np.zeros(maxEpisodes)\n",
    "    obs = Env.reset(seed=0)\n",
    "    sum =0\n",
    "    opti=0\n",
    "    \n",
    "    while e < maxEpisodes :\n",
    "        a = Q.argmax()\n",
    "        R = Env.step(a)[1]\n",
    "        sum = sum + R\n",
    "        N[a]= N[a]+1\n",
    "        Q[a]= Q[a] + ((R - Q[a])/N[a])\n",
    "        Q_est[e]=Q\n",
    "        if max(Q) == Q[a]:\n",
    "            opti+=1\n",
    "        #change R_est according to need of question \n",
    "        R_est[e]= (opti/e)*100\n",
    "        e=e+1\n",
    "        obs = Env.reset(seed=0)\n",
    "    \n",
    "#     print(\" left-action | right-action  | reward\")\n",
    "#     for i in range(maxEpisodes):\n",
    "#         print(f\"{Q_est[i][0]:12.6f} | {Q_est[i][1]:13.6f} | {R_est[i]:6.2f}\")\n",
    "        \n",
    "    return R_est     \n",
    "\n",
    "    \n",
    "ev = make('BBandit', alpha = 0.5 , beta = 0.5)\n",
    "PureExploitation(ev , 10)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce8c8d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.        , 100.        ,  50.        ,  33.33333333,\n",
       "        25.        ,  20.        ,  16.66666667,  14.28571429,\n",
       "        25.        ,  22.22222222])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploration Stratergy - Pure Exploration \n",
    "\n",
    "def PureExploration(Env , maxEpisodes):\n",
    "    \n",
    "    Q = np.zeros(Env.action_space_size)\n",
    "    N = np.zeros(Env.action_space_size)\n",
    "    e=1\n",
    "    Q_est = np.zeros((maxEpisodes,Env.action_space_size))\n",
    "    R_est = np.zeros(maxEpisodes)\n",
    "    observation, info = Env.reset(seed=0)\n",
    "    sum=0\n",
    "    opti=0\n",
    "    \n",
    "    while e < maxEpisodes :\n",
    "        a = np.random.randint(0,len(Q))\n",
    "        R = Env.step(a)[1]\n",
    "        sum += R\n",
    "        N[a]= N[a]+1\n",
    "        Q[a]= Q[a] + ((R - Q[a])/N[a])\n",
    "        Q_est[e]=Q\n",
    "        if max(Q)==Q[a]:\n",
    "            opti+=1\n",
    "        R_est[e]=(opti/e)*100\n",
    "        e=e+1\n",
    "        observation, info = Env.reset(seed=0)\n",
    "    \n",
    "#     print(\" left-action | right-action  | reward\")\n",
    "#     for i in range(maxEpisodes):\n",
    "#         print(f\"{Q_est[i][0]:12.6f} | {Q_est[i][1]:13.6f} | {R_est[i]:6.2f}\")\n",
    "\n",
    "    return R_est\n",
    "    \n",
    "ev = make('BBandit', alpha = 0.5 , beta = 0.5)\n",
    "PureExploration(ev , 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9be70beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.        , 100.        , 100.        , 100.        ,\n",
       "       100.        , 100.        ,  83.33333333,  85.71428571,\n",
       "        75.        ,  66.66666667])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epsilon - Greedy stratergy\n",
    "\n",
    "def EpsilonGreedy(Env , maxEpisodes , epsilon = 0.5):\n",
    "    \n",
    "    Q = np.zeros(Env.action_space_size)\n",
    "    N = np.zeros(Env.action_space_size)\n",
    "    e=1\n",
    "    Q_est = np.zeros((maxEpisodes,Env.action_space_size))\n",
    "    R_est = np.zeros(maxEpisodes)\n",
    "    observation, info = Env.reset(seed=0)\n",
    "    sum=0\n",
    "    opti=0\n",
    "    while e < maxEpisodes :\n",
    "        temp = np.random.randint(0,1)\n",
    "        if temp > epsilon :\n",
    "            a=Q.argmax()\n",
    "        else :\n",
    "            a=np.random.randint(0,len(Q))\n",
    "        R = Env.step(a)[1]\n",
    "        sum += R\n",
    "        N[a]= N[a]+1\n",
    "        Q[a]= Q[a] + ((R - Q[a])/N[a])\n",
    "        Q_est[e]=Q\n",
    "        if max(Q)==Q[a]:\n",
    "            opti+=1\n",
    "        R_est[e]=(opti/e)*100\n",
    "        e=e+1\n",
    "        observation, info = Env.reset(seed=0)\n",
    "    \n",
    "#     print(\" left-action | right-action  | reward\")\n",
    "#     for i in range(maxEpisodes):\n",
    "#         print(f\"{Q_est[i][0]:12.6f} | {Q_est[i][1]:13.6f} | {R_est[i]:6.2f}\")\n",
    "    \n",
    "    return R_est \n",
    "\n",
    "\n",
    "ev = make('BBandit', alpha = 0.5 , beta = 0.5)\n",
    "#ep = float(input(\"Enter the value of epsilon between 0 and 1 = \"))\n",
    "EpsilonGreedy(ev , 10 , 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82f8a26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.        , 100.        ,  50.        ,  66.66666667,\n",
       "        75.        ,  80.        ,  83.33333333,  85.71428571,\n",
       "        87.5       ,  88.88888889])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decaying epsilon - Greedy stratergy\n",
    "\n",
    "def decayingEpsilonGreedy(Env , maxEpisodes , choice = 0):\n",
    "    \n",
    "    Q = np.zeros(Env.action_space_size)\n",
    "    N = np.zeros(Env.action_space_size)\n",
    "    e=1\n",
    "    sum=0\n",
    "    opti=0\n",
    "    Q_est = np.zeros((maxEpisodes,Env.action_space_size))\n",
    "    R_est = np.zeros(maxEpisodes)\n",
    "    observation, info = Env.reset(seed=0)\n",
    "    epsilon = 1 \n",
    "    while e < maxEpisodes :\n",
    "        if choice == 0:\n",
    "            #linear decay\n",
    "            epsilon = epsilon - (e/maxEpisodes)\n",
    "        else :\n",
    "            #exponential decay\n",
    "            epsilon = epsilon * math.exp(-(e/maxEpisodes))\n",
    "            \n",
    "            \n",
    "        temp = np.random.randint(0,1)\n",
    "        if temp > epsilon :\n",
    "            a=Q.argmax()\n",
    "        else :\n",
    "            a=np.random.randint(0,len(Q))\n",
    "        R = Env.step(a)[1]\n",
    "        sum += R\n",
    "        N[a]= N[a]+1\n",
    "        Q[a]= Q[a] + ((R - Q[a])/N[a])\n",
    "        Q_est[e]=Q\n",
    "        if max(Q)==Q[a]:\n",
    "            opti+=1\n",
    "        R_est[e]=(opti/e)*100\n",
    "        e=e+1\n",
    "        observation, info = Env.reset(seed=0)\n",
    "    \n",
    "#     print(\" left-action | right-action  | reward\")\n",
    "#     for i in range(maxEpisodes):\n",
    "#         print(f\"{Q_est[i][0]:12.6f} | {Q_est[i][1]:13.6f} | {R_est[i]:6.2f}\")\n",
    "    \n",
    "    return R_est\n",
    "\n",
    "\n",
    "ev = make('BBandit', alpha = 0.5 , beta = 0.5)\n",
    "#ep = float(input(\" Choose the type of decay , 0 -> linear , 1 -> exponential = \"))\n",
    "decayingEpsilonGreedy(ev , 10 , 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd667769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sc/63b24d_x7_q7jtckgsd8mx000000gn/T/ipykernel_80093/1431403319.py:21: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  probs = softmax(Q/t)\n",
      "/var/folders/sc/63b24d_x7_q7jtckgsd8mx000000gn/T/ipykernel_80093/1431403319.py:4: RuntimeWarning: invalid value encountered in subtract\n",
      "  e_x = np.exp(x - np.max(x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  0.        , 100.        ,  50.        ,  33.33333333,\n",
       "        50.        ,  40.        ,  50.        ,  57.14285714,\n",
       "        50.        ,  55.55555556])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SoftMax stratergy\n",
    "def softmax(x):\n",
    "    #Compute softmax values for each sets of scores in x.\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "\n",
    "def Softmax(Env , maxEpisodes , t=10):\n",
    "    \n",
    "    Q = np.zeros(Env.action_space_size)\n",
    "    N = np.zeros(Env.action_space_size)\n",
    "    e=1\n",
    "    sum=0\n",
    "    opti=0\n",
    "    Q_est = np.zeros((maxEpisodes,Env.action_space_size))\n",
    "    R_est = np.zeros(maxEpisodes)\n",
    "    observation, info = Env.reset(seed=0)\n",
    "    t_not = copy.copy(t)\n",
    "    \n",
    "    while e < maxEpisodes :\n",
    "        probs = softmax(Q/t)\n",
    "        a= random.choices(range(Env.action_space_size), weights=probs, k=1)[0]\n",
    "        R = Env.step(a)[1]\n",
    "        sum+=R\n",
    "        N[a]= N[a]+1\n",
    "        Q[a]= Q[a] + ((R - Q[a])/N[a])\n",
    "        t = t - ((e/maxEpisodes)*t_not)   #linearly decaying temperature\n",
    "        Q_est[e]=Q\n",
    "        if max(Q)==Q[a]:\n",
    "            opti+=1\n",
    "        R_est[e]=(opti/e)*100\n",
    "        e=e+1\n",
    "        observation, info = Env.reset(seed=0)\n",
    "    \n",
    "#     print(\" left-action | right-action  | reward\")\n",
    "#     for i in range(maxEpisodes):\n",
    "#         print(f\"{Q_est[i][0]:12.6f} | {Q_est[i][1]:13.6f} | {R_est[i]:6.2f}\")\n",
    "    \n",
    "    return R_est\n",
    "\n",
    "\n",
    "ev = make('BBandit', alpha = 0.5 , beta = 0.5)\n",
    "#ep = float(input(\" Choose the value of Temperature = \"))\n",
    "Softmax(ev , 10 , 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0eb0d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0., 100., 100., 100., 100., 100., 100., 100., 100., 100.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UCB stratergy\n",
    "\n",
    "def UCB(Env , maxEpisodes , c=10):\n",
    "    \n",
    "    Q = np.zeros(Env.action_space_size)\n",
    "    N = np.zeros(Env.action_space_size)\n",
    "    e=1\n",
    "    sum=0\n",
    "    Q_est = np.zeros((maxEpisodes,Env.action_space_size))\n",
    "    R_est = np.zeros(maxEpisodes)\n",
    "    observation, info = Env.reset(seed=0)\n",
    "    opti=0\n",
    "    \n",
    "    while e < maxEpisodes :\n",
    "        if e < len(Q) :\n",
    "            a=e\n",
    "        else :\n",
    "            U = c * math.sqrt(math.log(e,10)/N[a])\n",
    "            a= (Q+U).argmax()\n",
    "        R = Env.step(a)[1]\n",
    "        sum+=R\n",
    "        N[a]= N[a]+1\n",
    "        Q[a]= Q[a] + ((R - Q[a])/N[a])\n",
    "        if max(Q) == Q[a]:\n",
    "            opti+=1\n",
    "        Q_est[e]=Q\n",
    "        R_est[e]= (((opti)/e)*100)\n",
    "        e=e+1\n",
    "        observation, info = Env.reset(seed=0)\n",
    "    \n",
    "#     print(\" left-action | right-action  | reward\")\n",
    "#     for i in range(maxEpisodes):\n",
    "#         print(f\"{Q_est[i][0]:12.6f} | {Q_est[i][1]:13.6f} | {R_est[i]:6.2f}\")\n",
    "    \n",
    "    return R_est\n",
    "\n",
    "\n",
    "ev = make('BBandit', alpha = 0.5 , beta = 0.5)\n",
    "#ep = float(input(\" Choose the value of c = \"))\n",
    "UCB(ev , 10 , 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d605824a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kislayadityaoj/opt/anaconda3/lib/python3.9/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.action_space_size to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.action_space_size` for environment variables or `env.get_wrapper_attr('action_space_size')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/kislayadityaoj/opt/anaconda3/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:127: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method should be an int or np.int64, actual type: <class 'dict'>\u001b[0m\n",
      "  logger.warn(f\"{pre} should be an int or np.int64, actual type: {type(obs)}\")\n",
      "/Users/kislayadityaoj/opt/anaconda3/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/Users/kislayadityaoj/opt/anaconda3/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:127: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method should be an int or np.int64, actual type: <class 'dict'>\u001b[0m\n",
      "  logger.warn(f\"{pre} should be an int or np.int64, actual type: {type(obs)}\")\n",
      "/Users/kislayadityaoj/opt/anaconda3/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Question 1 . 4 \n",
    "y_axis1 = np.zeros(1000)\n",
    "y_axis2 = np.zeros(1000)\n",
    "y_axis3 = np.zeros(1000)\n",
    "y_axis4 = np.zeros(1000)\n",
    "y_axis5 = np.zeros(1000)\n",
    "y_axis6 = np.zeros(1000)\n",
    "for j in range(50):\n",
    "    a = np.random.normal(loc=0, scale=1)\n",
    "    b = np.random.normal(loc=0, scale=1)\n",
    "\n",
    "    ev = make('BBandit', alpha = a , beta = b)\n",
    "\n",
    "    y_axis1 = y_axis1 + PureExploitation(ev,1000)\n",
    "    y_axis2 = y_axis2 + PureExploration(ev,1000)\n",
    "    y_axis3 = y_axis3 + EpsilonGreedy(ev,1000)\n",
    "    y_axis4 = y_axis4 + decayingEpsilonGreedy(ev,1000)\n",
    "    y_axis5 = y_axis5 + Softmax(ev,1000)\n",
    "    y_axis6 = y_axis6 + UCB(ev,1000)\n",
    "        \n",
    "# Average the accumulated data\n",
    "y_axis1 /= 50\n",
    "y_axis2 /= 50\n",
    "y_axis3 /= 50\n",
    "y_axis4 /= 50\n",
    "y_axis5 /= 50\n",
    "y_axis6 /= 50\n",
    "   \n",
    "x_axis = np.linspace(1,1000,1000)    \n",
    "\n",
    "# Plot the data\n",
    "plt.plot(x_axis, y_axis1, label='PureExploitation')\n",
    "plt.plot(x_axis, y_axis2, label='PureExploration')\n",
    "plt.plot(x_axis, y_axis3, label='EpsilonGreedy')\n",
    "plt.plot(x_axis, y_axis4, label='DecayingEpsilonGreedy')\n",
    "plt.plot(x_axis, y_axis5, label='Softmax')\n",
    "plt.plot(x_axis, y_axis6, label='UCB')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.title('Optimal action vs. Episode')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Optimal action %')\n",
    "plt.legend()\n",
    "\n",
    "plt.xscale('log')\n",
    "\n",
    "#plt.savefig(\"opti3.png\", format=\"png\", dpi=1200)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3d0c4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kislayadityaoj/opt/anaconda3/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df77c45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
