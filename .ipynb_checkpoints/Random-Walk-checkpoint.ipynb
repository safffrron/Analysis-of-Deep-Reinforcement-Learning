{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0c6a21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all useful functions \n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import gymnasium as gym\n",
    "from gymnasium import Env, spaces, register, make\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15efc6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomWalk(Env):\n",
    "    \n",
    "    \n",
    "    #----- 1 -----\n",
    "    #constructor for initialization and some helper functions\n",
    "    \n",
    "    \n",
    "    def __init__(self , start=3):\n",
    "        \n",
    "        #P is basically State: Action: [ Transition Probability , Next state , Reward , isTerminated?]\n",
    "        self.P = {\n",
    "            0: {\n",
    "                0: [(1.0, 0, 0.0, True)],\n",
    "                1: [(1.0, 0, 0.0, True)]\n",
    "            },\n",
    "            1: {\n",
    "                0: [(0.5, 0, 0.0, True), (0.5, 2, 0.0, False)],\n",
    "                1: [(0.5, 2, 0.0, False), (0.5, 0, 0.0, True)]\n",
    "            },\n",
    "            2: {\n",
    "                0: [(0.5, 1, 0.0, False), (0.5, 3, 0.0, False)],\n",
    "                1: [(0.5, 3, 0.0, False), (0.5, 1, 0.0, False)]\n",
    "            },\n",
    "            3: {\n",
    "                0: [(0.5, 2, 0.0, False), (0.5, 4, 0.0, False)],\n",
    "                1: [(0.5, 4, 0.0, False), (0.5, 2, 0.0, False)]\n",
    "            },\n",
    "            4: {\n",
    "                0: [(0.5, 3, 0.0, False), (0.5, 5, 0.0, False)],\n",
    "                1: [(0.5, 5, 0.0, False), (0.5, 3, 0.0, False)]\n",
    "            },\n",
    "            5: {\n",
    "                0: [(0.5, 6, 1.0, True), (0.5, 4, 0.0, False)],\n",
    "                1: [(0.5, 4, 0.0, False),(0.5, 6, 1.0, True)]\n",
    "            },\n",
    "            6: {\n",
    "                0: [(1.0, 6, 0.0, True)],\n",
    "                1: [(1.0, 6, 0.0, True)]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        self.size = 7 # The size of the 1D grid\n",
    "        #self.window_size = 512  # The size of the PyGame window\n",
    "        \n",
    "        # We have 3 observations, corresponding to each position in the 1-D grid\n",
    "        self.observation_space = spaces.Discrete(self.size)\n",
    "\n",
    "        # We have 2 actions, corresponding to \"left\" & \"right\"\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "        self.act_space_size = 2 \n",
    "        self.starting_pos = start\n",
    "        \n",
    "    \n",
    "    #return the locations of agent and target\n",
    "    def _get_obs(self):\n",
    "        return {   \n",
    "            \"agent\" : self._agent_location, \n",
    "            \"target\": self._target_location  \n",
    "        }\n",
    "    \n",
    "    #returns the distance between agent and target \n",
    "    def _get_info(self):\n",
    "        return {  \n",
    "            \"distance\": abs(self._agent_location - self._target_location)   \n",
    "        }\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #----- 2 ------\n",
    "    # The reset function to initiate \n",
    "    \n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        \n",
    "        self._agent_location = self.starting_pos  #location of agent in the begining\n",
    "        self._target_location = self.size-1  #starting location of target in this case 2 \n",
    "        self._dead_state = 0                 #dead location\n",
    "        \n",
    "        \n",
    "        observation = self._get_obs()        #getting useful information\n",
    "        info = self._get_info()\n",
    "\n",
    "        return observation,info\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #------- 3 ---------\n",
    "    # The step function \n",
    "    \n",
    "    def step(self, action):  # takes action as a parameter\n",
    "\n",
    "        # gets the current location and stores the values from P set \n",
    "        prev_location = self._agent_location                                #gets location\n",
    "        transitions = self.P[prev_location][action]                         #gets the corresponding action tuple\n",
    "        probabilities, next_states, rewards, terminals = zip(*transitions)  #stores the value for use \n",
    "        \n",
    "        # Randomly select a transition based on the probabilities\n",
    "        # gives you random state based on your probabilities \n",
    "        index = random.choices(range(len(probabilities)), weights=probabilities, k=1)[0]\n",
    "        # stores the values \n",
    "        self._agent_location, reward, terminated = next_states[index], rewards[index], terminals[index]\n",
    "        \n",
    "        truncated = False\n",
    "        observation = self._get_obs()  \n",
    "        info = self._get_info()\n",
    "\n",
    "        info[\"log\"] = {\"current_state\": prev_location, \n",
    "                       \"action\":action,  \n",
    "                        \"next_state\": self._agent_location}\n",
    "\n",
    "        # Return the required 5-tuple\n",
    "        return observation, reward, terminated, truncated, info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2900485e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the custom environment\n",
    "register(id='RandomWalk', entry_point=RandomWalk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25c8fd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'current_state': 3, 'action': 1, 'next_state': 2}\n",
      "{'current_state': 2, 'action': 1, 'next_state': 1}\n",
      "{'current_state': 1, 'action': 1, 'next_state': 0}\n",
      "Terminated \n",
      "\n",
      " Reward =  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kislayadityaoj/opt/anaconda3/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:127: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method should be an int or np.int64, actual type: <class 'dict'>\u001b[0m\n",
      "  logger.warn(f\"{pre} should be an int or np.int64, actual type: {type(obs)}\")\n",
      "/Users/kislayadityaoj/opt/anaconda3/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/Users/kislayadityaoj/opt/anaconda3/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:127: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method should be an int or np.int64, actual type: <class 'dict'>\u001b[0m\n",
      "  logger.warn(f\"{pre} should be an int or np.int64, actual type: {type(obs)}\")\n",
      "/Users/kislayadityaoj/opt/anaconda3/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    }
   ],
   "source": [
    "# Create and use the environment\n",
    "environment = make('RandomWalk' )\n",
    "terminated = False\n",
    "reward_sum = 0\n",
    "observation = environment.reset(seed=0)\n",
    "while not terminated :\n",
    "    action = 1  # this is where you would insert your policy\n",
    "    observation, reward, terminated, truncated, info = environment.step(action)\n",
    "    reward_sum += reward\n",
    "    print(info['log'])\n",
    "\n",
    "    if terminated:\n",
    "        print(\"Terminated\", \"\\n\")\n",
    "\n",
    "    \n",
    "    if terminated or truncated:\n",
    "        observation = environment.reset(seed=0)\n",
    "        \n",
    "        \n",
    "print(\" Reward = \" , (reward_sum )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fbcaa11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 0, 0.0, 2), (2, 0, 0.0, 1), (1, 0, 0.0, 0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environment = make('RandomWalk')\n",
    "observation = environment.reset(seed=0)\n",
    "\n",
    "\n",
    "policy=0                #only for this particular case as anyways it will go left \n",
    "\n",
    "\n",
    "def generateTrajectory( Env , policy , maxSteps) :\n",
    "    experience = []\n",
    "    terminated = False\n",
    "    steps=1\n",
    "    while not terminated :\n",
    "        \n",
    "        action = policy\n",
    "        observation, reward, terminated, truncated, info = environment.step(action)\n",
    "        \n",
    "        experience.append( (info['log']['current_state'],info['log']['action'],reward,info['log']['next_state']) )\n",
    "        \n",
    "        if terminated or truncated:\n",
    "            observation = environment.reset(seed=0)\n",
    "            return experience\n",
    "            \n",
    "        if steps > maxSteps :\n",
    "            observation = environment.reset(seed=0)\n",
    "            return []\n",
    "        \n",
    "        steps+=1\n",
    "\n",
    "generateTrajectory(environment , policy , 100) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d05ac9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA180lEQVR4nO3dd3gU5drH8e+dTSUJJSShJYSgCNKFBIJUpSrVAiJFVBQVsL0eFctBj91jOTZEERUUQYoo2JAuirTQey8JLQEEkpCElOf9Y9YY6SSbzCZ7f67La3cnszu/INwzO/PM/YgxBqWUUp7By+4ASimlio8WfaWU8iBa9JVSyoNo0VdKKQ+iRV8ppTyIt90BLiY0NNTUqFHD7hhKKVWirFy58ogxJuzM5W5f9GvUqEF8fLzdMZRSqkQRkb3nWq6nd5RSyoNo0VdKKQ+iRV8ppTyI25/TV0qVDFlZWSQmJpKRkWF3FI/i7+9PREQEPj4+l7S+Fn2llEskJiYSHBxMjRo1EBG743gEYwxHjx4lMTGR6OjoS3rPRU/viMhnIpIkIhvyLQsRkTkist35WCHfz54SkR0islVEOudb3lRE1jt/9p7o3wqlSpWMjAwqVqyoBb8YiQgVK1a8rG9Xl3JOfxzQ5YxlI4B5xphawDzna0SkLtAXqOd8z4ci4nC+ZzQwBKjl/O/Mz1RKlXBa8Ivf5f6ZX7ToG2MWAcfOWNwTGO98Ph7olW/518aYTGPMbmAH0ExEqgBljTFLjNXL+Yt873G53FzDiimvs3zOlKLahFJKlUgFHb1TyRhzEMD5GO5cXg1IyLdeonNZNefzM5efk4gMEZF4EYlPTk6+7HBeJpvQrZNotvhezLf3w6kz91lKKWWP48eP8+GHH+a9PnDgALfeeusF37Nnzx7q16/vku27esjmub5nmAssPydjzBhjTIwxJiYs7Ky7iC/O4cPKTtN4P7sXrJsCo5rDphmX/zlKKeViZxb9qlWrMm3atGLbfkGL/mHnKRucj0nO5YlAZL71IoADzuUR51heZLpeE81Yn/68FvkRBFeGKXfA5AGQcqgoN6uUstGECRNo1qwZjRs35r777mPZsmU0bNiQjIwM0tLSqFevHhs2bGDhwoW0adOGm266ibp163L//feTm5sLwKRJk2jQoAH169fnySefzPvsoKAgnnnmGRo1akRcXByHDx8GIDk5mVtuuYXY2FhiY2NZvHgxAM8//zx333037dq1o2bNmrz33nsAjBgxgp07d9K4cWMef/zxfxzF79mzh9atW9OkSROaNGnCH3/84fI/o4IO2ZwJDAJecz7OyLd8ooi8DVTFumC73BiTIyIpIhIHLAPuAN4vVPKLCPB10LtpBJ/+kc3gJ38mfP0nsOBV2N0MOr8KjfuBXnRSqkj85/uNbDpw0qWfWbdqWZ7rXu+8P9+8eTOTJ09m8eLF+Pj4MHToULZu3UqPHj149tlnSU9PZ8CAAdSvX5+FCxeyfPlyNm3aRFRUFF26dGH69Olce+21PPnkk6xcuZIKFSrQqVMnvvvuO3r16kVaWhpxcXG8/PLLPPHEE3zyySc8++yzPPzwwzz66KO0atWKffv20blzZzZv3gzAli1bWLBgASkpKdSuXZsHHniA1157jQ0bNrBmzRrAKvR/CQ8PZ86cOfj7+7N9+3Zuv/12l/ceu2jRF5FJQDsgVEQSgeewiv0UERkM7AN6AxhjNorIFGATkA0MM8bkOD/qAayRQAHAz87/ilT/uCjG/r6byfEHebD9o1CnG8x8EGYMhfVTofu7UCGqqGMopYrBvHnzWLlyJbGxsQCkp6cTHh7OyJEjiY2Nxd/fP+9oG6BZs2bUrFkTgNtvv53ff/8dHx8f2rVrx1+nlfv378+iRYvo1asXvr6+dOvWDYCmTZsyZ84cAObOncumTZvyPvfkyZOkpKQA0LVrV/z8/PDz8yM8PDzv28H5ZGVlMXz4cNasWYPD4WDbtm0u+tP520WLvjHm9vP8qP151n8ZePkcy+MB11yJuETRoYG0rhXKxOX7eKDdFXiH1oI7f4L4T2Hu8/BhC2g/EprdC16Oi36eUurSXOiIvKgYYxg0aBCvvvrqP5YfOnSI1NRUsrKyyMjIIDAwEDh7qKOIYA0uPDcfH5+89zgcDrKzswHIzc1lyZIlBAQEnPUePz+/vOf533M+//vf/6hUqRJr164lNzcXf3//C65fEKW+986AuCgOnshg3hbnZQcvL6vID10KUS1g1pPw+Q2QvNXeoEqpQmnfvj3Tpk0jKcn6t37s2DH27t3LkCFDePHFF+nfv/8/ztEvX76c3bt3k5uby+TJk2nVqhXNmzfn119/5ciRI+Tk5DBp0iTatm17we126tSJDz74IO/1X6dtzic4ODjvm8CZTpw4QZUqVfDy8uLLL78kJyfnnOsVRqkv+u3rhFOlnD8Tlp7RWrp8JPSfBjd9DEe2wUetYNEbkJNlT1ClVKHUrVuXl156iU6dOtGwYUM6duzI+PHj8fb2pl+/fowYMYIVK1Ywf/58AFq0aMGIESOoX78+0dHR3HTTTVSpUoVXX32V6667jkaNGtGkSRN69ux5we2+9957xMfH07BhQ+rWrctHH310wfUrVqxIy5YtqV+/Po8//vg/fjZ06FDGjx9PXFwc27Zty/tW4kpyoa8z7iAmJsYU9kLG+/O289acbSz4VzuiQ8/xh5iaBD8/ARu/hUoNoOcHULVxobaplKfZvHkzV199td0xLsnChQt58803+eGHH+yO4hLn+rMXkZXGmJgz1y31R/oAtzWLxNtL+OrMo/2/BIVD73Fw21eQlgSfXA9znoOs9GLNqZRSRc0jin54sD+d61dm6spEMrIucI7s6m4wbJk1nHPxO9Ypn72uHyerlLJXu3btSs1R/uXyiKIPMDAuihPpWXy/9iL3hAVUsE7vDPwOck5bF3l/fAwyXDvmWCml7OAxRb95dAi1woPOvqB7PldcZ43wiRsKKz61hndun1O0IZVSqoh5TNEXEQbERbE28QRrE45f2pt8A6HLqzB4DvgFwVe3wvT7tIGbUqrE8piiD3BTk2qU8XVc+tH+XyJj4b5F0OYJ2DANPoiFDdPBzUc+KaXUmTyq6Jf196HXNdWYufYAJ05d5nh8bz+4/hkY8iuUi4Bpd1kN3E4eLJqwSqnLFhQUBFxau2JP5VFFH2BA8ygys3OZujLh4iufS+X6cM886PgC7JhrtW1e9YUe9SvlRoqjXfHFWiq4K48r+nWrlqVpVAW+WraP3NwCFmqHN7R8GB74Ayo3sJq4fdETju12bVilVIHkb1c8btw4br75Zrp06UKtWrV44okn8tabPXs2LVq0oEmTJvTu3ZvU1FQAXnjhBWJjY6lfvz5DhgzJ68nTrl07nn76adq2bcu7775b/L+YCxS0tXKJNjAuikcmr2HxziO0rlWASVr+UvEKGPQ9rBoHs0fC6Gvh+n9D8/u0gZvybD+PgEPrXfuZlRvADa8V6K1r1qxh9erV+Pn5Ubt2bR588EECAgJ46aWXmDt3LoGBgbz++uu8/fbbjBw5kuHDhzNy5EgABg4cyA8//ED37t0BaxKUX3/91WW/VnHzuCN9gBsaVCYk0PfyL+iei5cXxNxt3dRVozX88hR82gmSNhf+s5VSLtG+fXvKlSuHv78/devWZe/evSxdupRNmzbRsmVLGjduzPjx49m716oJCxYsoHnz5jRo0ID58+ezcePGvM+67bbb7Po1XMIjj/T9vB30iYlkzKKdHDyRTpVyZ7dEvWzlqkG/yVaf/p+fhI9aQ9snoOUj4O1b+M9XqiQp4BF5UTlXi2NjDB07dmTSpEn/WDcjI4OhQ4cSHx9PZGQkzz//PBkZGXk/L4omaMXJI4/0Afo3r44BJi3b57oPFYGGfWD4CqjbAxa8DGPawf6VrtuGUsol4uLiWLx4MTt27ADg1KlTbNu2La/Ah4aGkpqaWqzz1xYHjy36kSFluK52OJNWJJCVk+vaDw8MhVs/g76TIP0YjO0As/8Np0+5djtKqQILCwtj3Lhx3H777TRs2JC4uDi2bNlC+fLluffee2nQoAG9evXKm4mrtPCI1srns2BLEneNW8Gofk3o2rBKkWyDjBMwZySsHAchNaH7exDdumi2pZSNSlJr5dJGWytfojZXhRFRIYAvl+4puo34l7Pm4h30vTWWf3w3+P4Ra2eglFLFzKOLvsNL6N88iqW7jrH98LmnL3OZ6DbWuP4Ww2HVeBgVB9t+KdptKqXUGTy66AP0iYnA1+HFV668oHs+vmWg88sweC4ElIeJfeCbeyDtSNFvW6li4O6ni0ujy/0z9/iiXzHIj64Nq/DNykTSMovptuqIplYPn3ZPwcbvYFQzWD9NWzmoEs3f35+jR49q4S9GxhiOHj2Kv7//Jb/HI8fpn2lAXHW+Xb2fGWsO0K959eLZqLcvtBsBV/eAmcPhm8HWGP+ub1tj/pUqYSIiIkhMTCQ5OdnuKB7F39+fiIiIS17fo0fv/MUYw43v/Q7ATw+1QkSKdHtnyc2BZR/BvBfB4WM1c2syyLrbVymlCkBH71yAiDAwLorNB0+yat/x4g/g5YAWw2DoH1ClEfzwCHzRA47uLP4sSqlSTYu+U8/GVQn283ZNP56CCqlpDe3s/h4cXAujW8If71vfBJRSygW06DsF+nlzc5Nq/LjuIEdTM+0LIgJNB1kN3K64DmY/a93Re3jjxd+rlFIXoUU/nwFxUZzOyWVKfKLdUaBsVeg70WrncHwffNwGFrwC2TbukJRSJZ4W/XxqVQomrmYIE5fvJaegE6y4kgjUvwWGLbcef30dPm4LiUV7YVspVXpp0T/DwLgaJBxLZ9E2Nxp2FlgRbh4D/aZA5knrdM+sp+F0mt3JlFIljBb9M3SqV4mwYD++tPOC7vlc1RmGLrUmbVk6ypqpa1fJncFHKVX8ClX0ReRREdkoIhtEZJKI+ItIiIjMEZHtzscK+dZ/SkR2iMhWEelc+Piu5+Pw4vbYSBZsTSLhmBu2QvYvC93ehjt/AnFYQztnPgjpx+1OppQqAQpc9EWkGvAQEGOMqQ84gL7ACGCeMaYWMM/5GhGp6/x5PaAL8KGIuOVEsrc3r46XCBOXF0M/noKq0RIeWGxN0L56AoxqDlt+tDuVUsrNFfb0jjcQICLeQBngANATGO/8+Xigl/N5T+BrY0ymMWY3sANoVsjtF4kq5QLocHU4k1ckkJntxmPkfQKsu3fvmWdN3PJ1P5h6J6S60fUIpZRbKXDRN8bsB94E9gEHgRPGmNlAJWPMQec6B4Fw51uqAQn5PiLRuewsIjJEROJFJN6uPh4D4qI4lnaan9cfsmX7l6VaExiyEK571jraHxULaydrAzel1FkKc3qnAtbRezRQFQgUkQEXess5lp2zKhljxhhjYowxMWFhYQWNWCgtrwglOjTQPS/onovDB9o+Dvf/DhVrwbdDrNbNJ9zgngOllNsozOmdDsBuY0yyMSYLmA5cCxwWkSoAzsck5/qJQGS+90dgnQ5yS15eQv/m1Vm59082HThpd5xLF1Yb7p4FXV6HPb9bk7WsGAu5Lp4HWClVIhWm6O8D4kSkjFhtKdsDm4GZwCDnOoOAGc7nM4G+IuInItFALWB5IbZf5Ho3jcTfx4sJy0rI0f5fvBwQdz8MXWL17v/xMRjXFY7ssDuZUspmhTmnvwyYBqwC1js/awzwGtBRRLYDHZ2vMcZsBKYAm4BZwDBjjBtfJYVyZXzo3rAq363ez8mMLLvjXL4KNWDgd9BzFCRthI9awu/vQE4xTRajlHI72k//ItYlHqfHB4v5T496DLq2hm05Ci3lkHXEv+UHq31zz1FQuYHdqZRSRUT76RdQw4jyNIoox4Sle0v2NHDBleG2CdB7PJw8AGPawfyXtIGbUh5Gi/4l6B8XxfakVJbtPmZ3lMIRgXq9rAZuDfrAojfgo9aQ4NaXVpRSLqRF/xJ0b1iVcgE+JWf45sWUCYGbRsOAbyDrFHzaCX4eAZmpdidTShUxLfqXIMDXQe+mEfyy4RBJJzPsjuM6V3awRvg0uxeWjYbRLWDnfLtTKaWKkBb9S9Q/LorsXMPkFQkXX7kk8QuGG9+Au2aBww++vAm+Gwbpf9qdTClVBLToX6Lo0EBa1wpl4vJ9ZOeUwhudolpYd/O2+j9YO8lq4Lb5e7tTKaVcTIv+ZRgQF8XBExnM25J08ZVLIh9/6PAc3DsfgsJh8gCYcgekHLY7mVLKRbToX4b2dcKpUs6fCaXlgu75VG0M9y6A9iNh6ywY1QzWTNIGbkqVAlr0L4O3w4t+zarz2/Yj7D5SyqcqdPhA68esUz5hdeC7+2HCLdYk7UqpEkuL/mW6rVkk3l7CV6X9aP8vYVfBXT/DDW/AvqXwYQtY/ok2cFOqhNKif5nCg/3pXL8yU1cmkpHl1q2DXMfLC5oPgWFLIbI5/PQvGHcjHNludzKl1GXSol8AA+OiOJGexfdr3bYzdNEoX926oavXaEjaDKNbwm9vQU4JbEanlIfSol8AzaNDqBUeVPov6J6LCDTuZ7VyqN0F5r0An1wPB9fanUwpdQm06BeAiDAgLoq1iSdYm3Dc7jj2CK4Efb6APl9aHTzHXAdz/wNZpeiOZaVKIS36BXRTk2qU8XV45tF+fnV7wPDl0Oh2+P1t+KiVdcFXKeWWtOgXUFl/H3pdU42Zaw9w4pSHn9MOqAC9RsGA6ZCTCZ91gZ8eh8wUu5Mppc6gRb8QBjSPIjM7l6krS1k/noK6sj08sASa32cN6/ywBeyYa3cqpVQ+WvQLoW7VsjSNqsBXy/aRm6t3qwLgFwQ3vA53/wI+AdYNXd/eD6dK+FwESpUSWvQLaWBcFLuPpLF45xG7o7iX6s3hvt+g9b9g/VSrlcPG7+xOpZTH06JfSDc0qExIoK9e0D0XH39o/2+rj0/ZqjB1kNXELeWQ3cmU8lha9AvJz9vBbbGRzNl0mIMn0u2O456qNIR75kOH52HbbOuof/UEbeCmlA206LtAv2bVMcCkZdqM7Lwc3tDqUXjgDwivBzOGWRO2/KnfkJQqTlr0XSAypAzX1Q5n0ooEskrjBCuuFHol3PkjdH0LEldYI3yWfgS5HtLHSCmbadF3kYFxUSSnZDJ7o044clFeXhB7DwxdClHXwqwnrbH9yVvtTqZUqadF30XaXBVGZEgAXy7dY3eUkqN8JPSfCjeNgaPbrbt5F72hDdyUKkJa9F3E4SX0axbF0l3H2H5Y70S9ZCLQ6DYYtgLqdIX5L8GYdnBgtd3JlCqVtOi7UJ+YCHwdXjp8syCCwqD3OLjtK0g7Ap+0hznPQZaOiFLKlbTou1DFID+6NqzC9FX7tR9PQV3dDYYtg2v6w+J3rJ79exbbnUqpUkOLvosNaVOTU1k5vPjjJrujlFwB5aHH+3DHDMjNtmbp+uH/IOOk3cmUKvG06LvY1VXK8kDbK5i2MpGFW5PsjlOy1WwHQ5dA3DCI/8wa3rlttt2plCrRtOgXgQfbX8mV4UE8PX09KRl6mqdQfAOhyysweI7VzG1ib5g+BNKO2p1MqRKpUEVfRMqLyDQR2SIim0WkhYiEiMgcEdnufKyQb/2nRGSHiGwVkc6Fj++e/Lwd/PfWhhw8mcHrs7bYHad0iIyF+xZB2ydhwzdWK4cN07WVg1KXqbBH+u8Cs4wxdYBGwGZgBDDPGFMLmOd8jYjUBfoC9YAuwIci4ijk9t1Wk+oVuLtlNBOW7mPJTj0qdQlvP7juaRjyqzXGf9pd8HV/OHnQ7mRKlRgFLvoiUhZoA3wKYIw5bYw5DvQExjtXGw/0cj7vCXxtjMk0xuwGdgDNCrr9kuBfnWoTVbEMI6avI/20thlwmcr1YfBc6Pgi7JwHo5rDqi/0qF+pS1CYI/2aQDLwuYisFpGxIhIIVDLGHARwPoY7168G5J9iKtG57CwiMkRE4kUkPjk5uRAR7RXg6+C1mxuy9+gp3pqtLQZcyuENLR+yGrhVbgAzH4QvesCx3XYnU8qtFaboewNNgNHGmGuANJyncs5DzrHsnIdmxpgxxpgYY0xMWFhYISLar8UVFenfvDqfLd7Nqn1/2h2n9Kl4BQz6Hrq9A/tXWyN8lozSBm5KnUdhin4ikGiMWeZ8PQ1rJ3BYRKoAOB+T8q0fme/9EcCBQmy/xBhxQx0ql/XniWnryMzWYuRyXl4Qc5d1U1d0G/jlafi0EyRttjuZUm6nwEXfGHMISBCR2s5F7YFNwExgkHPZIGCG8/lMoK+I+IlINFALWF7Q7Zckwf4+vHJzA3YkpfL+vB12xym9ylWDfpPhlk/hz93wUWtY+Dpkn7Y7mVJuo7Cjdx4EvhKRdUBj4BXgNaCjiGwHOjpfY4zZCEzB2jHMAoYZYzzmsLdd7XBuaRLB6F93smH/CbvjlF4i0OBWGLYc6vaEha/AmLawf6XdyZRyC2LcfMRDTEyMiY+PtzuGSxw/dZqO/1tEWJAfM4a3xMeh98YVua0/Wy0cUg9B3FC47hnwLWN3KqWKnIisNMbEnLlcq04xKl/Glxd71mfTwZOMWbTL7jieofYNMGwpNBkESz6A0dfC7t/sTqWUbbToF7Mu9SvTtWEV3p27XfvuFxf/ctD9HWuUD8D4bvD9w5Chp9mU59Gib4P/9KhHoJ+DJ75ZR06ue59eK1Wi21jj+q990LqZa1QcbJ1ldyqlipUWfRuEBvnxfI96rN53nM8X681Excq3DHR6ybqjN6A8TLoNpg22Jm5RygNo0bdJj0ZVaV8nnDdnb2XPkTS743ieiKZWD592T8OmGfBBLKybqq0cVKmnRd8mIsLLNzXAx8uLEdPXkauneYqfty+0e9Lq3hkSDdPvgUl94cR+u5MpVWS06Nuocjl/nu12NUt3HWPi8n12x/Fclepa/fo7vwK7frUauMV/Brm5didTyuW06NusT0wkra4M5bWft7D/uE4CbhsvB7QYBkP/gGrXwA+PWg3cju60O5lSLqVF32Yiwqs3NyDXGJ6evh53v1mu1AupCXfMhO7vwcG11rj+xe9BTrbdyZRyCS36biAypAxPdK7Nr9uS+WaVnk+2nQg0HWQ1cLviepjzb/i0AxzaYHcypQpNi76buKNFDWKiKvDC9xtJOplhdxwFULYq9J0It34GxxOsHj4LXoHsTLuTKVVgWvTdhJeX8N9bG5KZncu/Z2zQ0zzuQgTq32I1cKt/C/z6OnzcBhJW2J1MqQLRou9GaoYF8WjHq/hl42F+Wn/I7jgqv8CKcPMY6DcFMlPg044w6yk4rfdYqJJFi76buadVNA0jyjFyxgaOpWkfeLdzVWcYutSatGXph9ZMXbsW2p1KqUumRd/NeDu8+O+tDTmZkcV/vt9odxx1Lv5lodv/4M4fwcsbvugJM4ZD+nG7kyl1UVr03VCdymUZdt2VzFhzgLmbDtsdR51PjVbwwGJo+TCs+cq6qWvLj3anUuqCtOi7qaHtrqRO5WCe+W49J9Kz7I6jzscnADq+APfMg8BQ+LofTL0TUpMu+lal7KBF3035eluneZJTMnn1J53g2+1VawJDFsJ1z1pH+6OawdrJ2sBNuR0t+m6sYUR5hrS5gq9XJPD7dm396/YcPtD2cbjvN6hYC74dAl/1tsb4K+UmtOi7uUc61KJmaCAjpq8jLVNbAZQI4XXg7lnQ5XXYuxg+jIPln2gDN+UWtOi7OX8fB/+9tSH7j6fzxi9b7Y6jLpWXA+Luh6FLICIGfvoXjOsKR3bYnUx5OC36JUBMjRAGtajBuD/2sGLPMbvjqMtRoQYM/A56joKkjVYDt9//pw3clG206JcQj3euTUSFAJ6cto6MrBy746jLIQLXDLBaOdTqCHOfh7HXw6H1didTHkiLfgkR6OfN67c0ZNeRNP43d5vdcVRBBFeG2yZA7/Fw8gCMaQfzXoQsbbCnio8W/RKk5ZWh9I2N5JNFu1ibcNzuOKogRKBeL+uov0Ef+O1N+Lg17FtmdzLlIbTolzBPd72a8GB/npi2jtPZOhqkxCoTAjeNhgHfQFY6fNYZfn4SMlPtTqZKOS36JUxZfx9evqk+Ww+nMGqBjgQp8a7sYI3waXYvLPvIauC2Y57dqVQppkW/BGp/dSV6Na7KqAU72HzwpN1xVGH5BcONb8Bds8DbDybcDN8NhfQ/7U6mSiEt+iXUyO71KBfgwxPT1pGdo6d5SoWoFnD/79Dq/2Dt11YDt00z7U6lShkt+iVUSKAvL/Ssz/r9Jxj7+2674yhX8fGHDs/BkAUQFA5TBsLkgZCi3VaVa2jRL8FubFCZLvUq8/acbexM1guApUqVRnDvAmg/Erb9YjVwWzNRG7ipQit00RcRh4isFpEfnK9DRGSOiGx3PlbIt+5TIrJDRLaKSOfCbtvTiQgv9KpHgI+DJ6etIzdXC0Kp4vCB1o9Zp3zC6sB3D8CEW+D4PruTqRLMFUf6DwP5e/+OAOYZY2oB85yvEZG6QF+gHtAF+FBEHC7YvkcLD/ZnZLe6xO/9ky+W7LE7jioKYVfBXT/DjW9CwjIYFQfLxmgDN1UghSr6IhIBdAXG5lvcExjvfD4e6JVv+dfGmExjzG5gB9CsMNtXlpubVKPtVWG8PmsrCcdO2R1HFQUvL2tY59AlUD0Ofn4cPr8BkvXubHV5Cnuk/w7wBJD/kKOSMeYggPMx3Lm8GpC/sXiic9lZRGSIiMSLSHxycnIhI5Z+IsIrNzfA4SUM+mw5B0+k2x1JFZXy1a0bunp9BMlb4KOWsOhNyNHZ1dSlKXDRF5FuQJIxZuWlvuUcy855EtoYM8YYE2OMiQkLCytoRI9SrXwAn98VS1JKJn0+XqJH/KWZCDS+HYavgNo3wPwX4ZPr4OBau5OpEqAwR/otgR4isgf4GrheRCYAh0WkCoDz8a/JQhOByHzvjwAOFGL76gyxNUKYcE9zTpzK4raPl7D7SJrdkVRRCgqHPl9Any+tOXnHXGd18MzSb3rq/Apc9I0xTxljIowxNbAu0M43xgwAZgKDnKsNAmY4n88E+oqIn4hEA7WA5QVOrs6pcWR5Jg2JIyM7lz4fL2H74RS7I6miVrcHDFsGjW63evV/1Ar2LrE7lXJTRTFO/zWgo4hsBzo6X2OM2QhMATYBs4BhxhhtDF8E6lUtx+QhcQDcNmYpGw+csDmRKnIBFaDXKBj4LeSchs+7wI//gkzd6at/EuPmN3vExMSY+Ph4u2OUSLuPpNH/k6WkZmbzxeDmNI4sb3ckVRwyU2H+S1YDt7LVoPu7UKuD3alUMRORlcaYmDOX6x25pVh0aCCT72tBuTI+DBi7TKda9BR+QXDDazB4NvgGwle3wLf3wyn9/6+06Jd6kSFlmHrftYQH+3HHp8v5Y8cRuyOp4hLZDO7/Ddo8DuunWq0cNn6rrRw8nBZ9D1C5nD+T72tB9ZAy3DluBQu2JF38Tap08PaD65+FIQutUz1T74TJAyDlkN3JlE206HuIsGA/Jg2J46pKQQz5Mp5ZG/QfvUep3ADumQcd/gM75sIHzWDVl3rU74G06HuQkEBfvronjvrVyjFs4ipmrtXbJDyKwxtaPQL3L4bK9WHmcPiyF/y5x+Zgqjhp0fcw5QJ8+HJwc5pGVeDhr1czNT7h4m9SpUvolTDoB+j6NiSutKZoXDoacnUEtSfQou+Bgvy8GX9XM1pdGcrj09bx5dK9dkdSxc3LC2IHw7ClENUSZo2wJmdP2mJ3MlXEtOh7qABfB5/cEUOHq8P593cbGPvbLrsjKTuUi4D+U+HmT+DoTvi4Nfz6X8g+bXcyVUS06Hswfx8HH/Zvyo0NKvPSj5v5YP52uyMpO4hAwz4wbDnU6QYLXrYauO1fZXcyVQS06Hs4X28v3ut7DTddU403Z2/jzV+24u53aasiEhQGvT+HvhMh7QiMbQ+z/60N3EoZb7sDKPt5O7x4q3cj/Ly9+GDBDjKycnim69WInKsbtir16nS1zvPPGQl/vAdbfoAe70ONVnYnUy6gR/oKAC8v4ZWbGnDntTUY+/tu/j1jg86568kCykOP9+COmWByYVxX+OFRyDhpdzJVSFr0VR4vL+G57nW5r21NJizdx5PfrCNHC79nq9kWHvgDWgyHlePgwzjY9ovdqVQhaNFX/yAijOhSh0c61GLqykQenbyGrBydgNuj+QZC55dh8BzwC4aJfeCbeyHtqN3JVAFo0VdnEREe6XAVT3apw8y1Bxg+cRWns7Xwe7yIGLhvEbQdARunw6hYWD9NWzmUMFr01Xk90O4Knutel182Hua+L+PJyNI7Nj2etx9c95RV/MtXh28Gw9f94KS29CgptOirC7qrZTSv3NSAhduSuXvcCk6dzrY7knIHlerB4LnQ6SXYuQBGNbfO+etRv9vToq8uql/z6rzVuxFLdx1l0GfLScnIsjuScgcOb7j2QXhgMVRpBN8/DOO7wzG9u9udadFXl+TmJhG8f3sTVu87zoBPl3PilBZ+5VTxCmtoZ7d34OBa+PBa+OMDbeDmprToq0vWtWEVRg9oyuYDJ7n9k6UcTc20O5JyF15eEHMXDF1qDfOc/Qx82hEOb7I7mTqDFn11WTrWrcTYQTHsOpJK3zFLSTqZYXck5U7KVYPbv4ZbPrX69H/cBha+pg3c3IgWfXXZ2lwVxri7mrH/eDp9Pl7CgePam0XlIwINbrUauNXrBQtfhTFtrd79ynZa9FWBxNWsyJeDm3M09TR9Pl7CvqOn7I6k3E1gKNwy1jryTz8On3aAX56B0/p3xU5a9FWBNY2qwMR740jNzObm0YuZsWa/duhUZ6t9gzVZS5NBsOQDGN0Cdi+yO5XH0qKvCqVBRDmm3teCquUDePjrNfQfu4wdSal2x1Luxr8cdH/HmqYRsYZ2znwIMk7YnczjiLsfmcXExJj4+Hi7Y6iLyMk1TFy+jzdmbSE9K4d7W9fkwetrEeDrsDuacjenT8HCV2DJKAiqBN3+Z30bUC4lIiuNMTFnLtcjfeUSDi9hYFwU8//Vjh6NqvHhwp10ePtX5mw6bHc05W58y1h38t4zFwJCYFJfmHa3NXGLKnJa9JVLhQb58VafRkweEkegn4N7v4hn8LgVJBzTi3fqDNWawpCF0O5p2DQTPoiFdVO1lUMR09M7qshk5eTy+eLdvDN3Ozm5hgevv5J729TEz1tP+agzJG2GGcNhfzzU6gzd3rYmbVcFdr7TO1r0VZE7eCKdF3/YxE/rD1EzNJD/9KxH61phdsdS7iY3B5Z9DPNfBHFApxegyZ3W3b7qsuk5fWWbKuUC+LB/U8bf3YxcYxj46XKGT1zFoRN6N6/Kx8sBLYZaM3VVa2JNzzi+OxzdaXeyUqXARV9EIkVkgYhsFpGNIvKwc3mIiMwRke3Oxwr53vOUiOwQka0i0tkVv4AqOdpeFcasR9rwaIermL3pMO3fWsjY33aRrTNzqfxCouGOGdZk7IfWw+hrYfG7kKNtvV2hwKd3RKQKUMUYs0pEgoGVQC/gTuCYMeY1ERkBVDDGPCkidYFJQDOgKjAXuMoYc8FWfHp6p3TaezSN52ZuZOHWZOpUDualXvWJqRFidyzlbk4ehB8fg60/QtVroMcHULm+3alKBJef3jHGHDTGrHI+TwE2A9WAnsB452rjsXYEOJd/bYzJNMbsBnZg7QCUB4qqGMjnd8by0YCmnEzP4taPlvD41LXauVP9U9kq0PcruPVzOJ5g9fCZ/zJk69+TgnLJOX0RqQFcAywDKhljDoK1YwDCnatVAxLyvS3RuexcnzdEROJFJD45OdkVEZUbEhG61K/M3Mfacn/bK/h29X6uf+tXvlq2l9xc9x5goIqRCNS/GYavgPq3wKL/Wt07E1bYnaxEKnTRF5Eg4BvgEWPMyQuteo5l5/yXbYwZY4yJMcbEhIXpKI/SroyvNyNuqMPPD7emTuVgnvl2AzeN/oP1iXqLvsqnTAjcPAb6TYXMVKtf/6yn4HSa3clKlEIVfRHxwSr4XxljpjsXH3ae7//rvH+Sc3kiEJnv7RGAzqas8tSqFMzXQ+J457bG7P8znZ6jfmfkjA2cSNdZulQ+V3WCoUsgdjAs/RA+bGHN06suSWFG7wjwKbDZGPN2vh/NBAY5nw8CZuRb3ldE/EQkGqgFLC/o9lXpJCL0uqYa8x5ry8C4KCYs3Uv7txby7epE7eCp/uZfFrq+BXf+BF7e8GUvmDHMauGsLqgwo3daAb8B64G/xtw9jXVefwpQHdgH9DbGHHO+5xngbiAb63TQzxfbjo7e8Wwb9p/gme82sDbhOM2jQ3ixV32uqhRsdyzlTrLSrdm5/ngfAsOsncHV3exOZTu9I1eVWLm5hq9XJPD6rC2kZWYzuHU0D11fi0A/b7ujKXdyYDXMeBAOr4e6veDGNyAo/KJvK6206KsS72hqJq/P2sKU+ESqlPPnue516VyvMtaZRqWAnCxY/A78+l/wDYQur0HD26wRQB5Gi74qNeL3HOPZ7zaw5VAK7WqH8VD7WlwTWV6Lv/pb8laY+SAkLIMrO1o9+8tHXvx9pYgWfVWqZOfkMu6PPbwzdzupmdnUCg+iT0wkva6pRliwn93xlDvIzYUVY2Hu89aRfofnIWawxzRw06KvSqWUjCx+XHeQKfEJrNp3HG8v4fo64fSJiaRd7TC8HZ7xD1xdwJ974fuHYdcCqH4t9HgPQmvZnarIadFXpd72wylMXZnI9FWJHEk9TViwH7c0iaB3TARXhAXZHU/ZyRhYMxF+eQqyMqDdCLj2IXCU3sEAWvSVx8jKyWXBliSmxCewYGsyObmGmKgK9ImNpGuDKjrqx5OlHIafHoPN30OVRlYDtyoN7U5VJLToK4+UdDKD6av3MyU+gV3JaZTxddCtYRX6xETSNKqCXvz1VJtmwI//glNHodUj0OYJ8PG3O5VLadFXHs0Yw6p9fzJ5RQI/rDvIqdM51AwLpE9MJDc3qUZ4cOn6B68uwalj8MszsHYihF5lHfVXb253KpfRoq+UU1pmNj+uP8jU+ARW7PkTh5dwXe0w+sREcl2dcHz04q9n2TEXvn8ETiRCsyHQfiT4lfxrQFr0lTqHXcmpTF2ZyDcrE0lKySQ0yJebm0TQJyaCK8O13YPHyEyBeS/C8jFQLhK6vwNXtrc7VaFo0VfqArJzcvl1WzJT4hOYtzmJ7FxDk+rl6RMTSdeGVQj297E7oioO+5bCjOFwdDs07g+dXrJaOpdAWvSVukRHUjP5dpV18Xd7UioBPg5ubFCF22Ijia2hF39LvawMa6KW39+BMhWh65tQt6fdqS6bFn2lLpMxhjUJx5kSn8j3aw+QmplNjYpl6B0TyS1NIqhcTi/+lmoH11ntmg+tg6t7wI1vQnAlu1NdMi36ShXCqdPZ/Lz+EFPiE1i2+xheAnE1KxJXsyLNokNoHFkefx+H3TGVq+VkWS2bF74GPgHQ+RVo3K9ENHDToq+Ui+w5ksbUlQnM35LMlkMnMQZ8HV40iixHs+gQmkVXpGlUBYL0JrDS48h2q4HbviVwxfXQ7R2oEGV3qgvSoq9UEThxKov4vcdYvvsYy3YfY/3+E+TkGhxeQr2qZWlWI4Rm0SHE1gihQqCv3XFVYeTmQvynVgM3Y6DDcxB7r9s2cNOir1QxSMvMZvW+4yzffZRlu4+xOuE4p7OtieVqVwp2fhOw/qtUVq8JlEjH98EPj1rj+yObQ4/3Iay23anOokVfKRtkZuewLvFE3jeBlXuOkXY6B4AaFcvknQ5qHh1CRIUAHRlUUhgD6ybDrBFwOg3aPgktHwaH+wzt1aKvlBvIzsll08GTeTuBFXuOcfxUFgBVyvnnfQtoHh3CFWFBuhNwd6lJ8NPjsOk7qNzAauVQtbHdqQAt+kq5pdxcw/ak1LzTQct3HyMpJROAkEDfvGsCzaJDuLpKWRxeuhNwS5u/hx8fg7Qj0PIh68jfJ8DWSFr0lSoBjDHsPXoq75vA8j1HSTiWDkCwnzdNa1QgtkYItSsFUzMskOohZXSiGHeR/ifM/jes/hIqXmmd64+61rY4WvSVKqEOHE9nxR7rW8Dy3cfYnpSa9zNvL6F6xTJcERZEzbBArgi1HmuGBRGio4XssXMBfP+QdcE39h5rmka/4u/jpEVfqVLixKksdh5JZVdyGjuTU9mVbD3fe/QUp3Ny89YrX8aHmqHWDqBmWCA1Q4O4MjyQ6iGB+Hrrt4MidToN5r8ES0dD2WpWA7daHYs1ghZ9pUq5nFxD4p+n/t4ZHEnL2yH8dZ0AwOElRFYIsHYG+XcKYYGEBfnpxWNXSlhuNXA7shUa9oUurxZbAzct+kp5sJSMLHYlp7HL+Q3hrx3D7iNpZGb//e0g2M877/TQFWF/7xBqVAzUNhMFlZ0Ji96E39+GgApw4xtQt1eRt3LQoq+UOkturuHAiXTnjiCVnfl2DAdPZOStJwLVygcQWaEM4WX9CAvyI7ysH+HB/oQF+xEebD0vG+Ct3xTO59AGq4HbwTVQpxt0fQuCKxfZ5rToK6Uuy6nT2c5vB3+fJjpwPJ2klEySUjLIyMo96z2+3l55O4Tz7RjCgv0IDfL1zFFHOdmwdBQseAUcftD5ZbhmQJEc9WvRV0q5jDGG1MxsawdwMpPk1EySTmaQnJJJckpm3o4hOSWTP503n+UnAhUDfQkN8iO8rD/hwX5n7RjCg62dRhnfUti47uhOq4Hb3sUQ3Ra6vwsh0S7dhBZ9pZQtMrNzOJJ62toZnMwgKd+OIdm5Y/hrWXbu2fUo0NdBWLAfZQN8KOvvQ9kAb4L9nI/+PpT1dz4G5H9uPQb7eePlrje05ebCys9hznNgcuD6f0Pz+8DLNddOtOgrpdxabq7heHoWSSkZ1reHfN8YjqSe5mR6FikZWZzMyLYe07NJz8q54GeKQJCfN2X9fQj2987baeS9Dvh7efB5fubnXcQXsE8kWg3cts+GiFirlUN4nUJ/rBZ9pVSpk5WTS0pGtnOHkM3JjKy8HcJJ5w7iXD9LyXQ+ZmRxji8X/+DtJQT4OPD3dRDg48h77u/tRcBZyxwE+HpZr30ceT/393GcY5nX35/r7YXPpunw8xNwOhXaPA4tHwHvgt9g5zZFX0S6AO8CDmCsMea1C62vRV8pVVSMMaSdzjn3jsG50zh1Opv007mkZ+WQkZVD+umcvOcZWdbz9Kwc0k/n5r3Oudie5By8vYSqPmk84/U5nc1idnlFUXX4T/iHRBTodztf0S/WKyQi4gBGAR2BRGCFiMw0xmwqzhxKKQUgIgT5ebt8lrOsHOdO4nT+nUIOGVl/7xjOufM4ncvCrNdJOLaIpn/+RFRZ1w/pLO7L4s2AHcaYXQAi8jXQE9Cir5QqNXwcXvg4vCjrX9D++g2AYa6MlKe4B8pWAxLyvU50LvsHERkiIvEiEp+cnFxs4ZRSqrQr7qJ/rrFTZ538MsaMMcbEGGNiwsLCiiGWUkp5huIu+olAZL7XEcCBYs6glFIeq7iL/gqglohEi4gv0BeYWcwZlFLKYxXrhVxjTLaIDAd+wRqy+ZkxZmNxZlBKKU9W7E0tjDE/AT8V93aVUkoV/+kdpZRSNtKir5RSHsTte++ISDKw1+4clykUOGJ3iGKmv7Nn0N+55Igyxpw15t3ti35JJCLx5+p5UZrp7+wZ9Hcu+fT0jlJKeRAt+kop5UG06BeNMXYHsIH+zp5Bf+cSTs/pK6WUB9EjfaWU8iBa9JVSyoNo0XchEYkUkQUisllENorIw3ZnKg4i4hCR1SLyg91ZiouIlBeRaSKyxfn/u4XdmYqSiDzq/Du9QUQmiYi/3ZmKgoh8JiJJIrIh37IQEZkjItudjxXszFhYWvRdKxt4zBhzNRAHDBORujZnKg4PA5vtDlHM3gVmGWPqAI0oxb+/iFQDHgJijDH1sZol9rU3VZEZB3Q5Y9kIYJ4xphYwz/m6xNKi70LGmIPGmFXO5ylYheCsmcFKExGJALoCY+3OUlxEpCzQBvgUwBhz2hhz3NZQRc8bCBARb6AMpXQeDGPMIuDYGYt7AuOdz8cDvYozk6tp0S8iIlIDuAZYZnOUovYO8ASQa3OO4lQTSAY+d57WGisigXaHKirGmP3Am8A+4CBwwhgz295UxaqSMeYgWAd2QLjNeQpFi34REJEg4BvgEWPMSbvzFBUR6QYkGWNW2p2lmHkDTYDRxphrgDRK+Ff+C3Gew+4JRANVgUARGWBvKlVQWvRdTER8sAr+V8aY6XbnKWItgR4isgf4GrheRCbYG6lYJAKJxpi/vsVNw9oJlFYdgN3GmGRjTBYwHbjW5kzF6bCIVAFwPibZnKdQtOi7kIgI1nnezcaYt+3OU9SMMU8ZYyKMMTWwLuzNN8aU+iNAY8whIEFEajsXtQc22RipqO0D4kSkjPPveHtK8YXrc5gJDHI+HwTMsDFLoRX7zFmlXEtgILBeRNY4lz3tnC1MlS4PAl8553reBdxlc54iY4xZJiLTgFVYI9RWU8paE/xFRCYB7YBQEUkEngNeA6aIyGCsHWBv+xIWnrZhUEopD6Knd5RSyoNo0VdKKQ+iRV8ppTyIFn2llPIgWvSVUsqDaNFXSikPokVfKaU8yP8DMHmT2E2+PFIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# decay-type : 0 -> linear decay , 1 -> exponential decay\n",
    "\n",
    "def decayAlpha(initialValue, finalValue, maxSteps, decayType) :\n",
    "    ans=[initialValue]\n",
    "    if decayType == 0 :\n",
    "        \n",
    "        steps= abs(finalValue-initialValue)/maxSteps \n",
    "        i = 1 \n",
    "        value = initialValue\n",
    "        while i <= maxSteps :\n",
    "            value = value - steps\n",
    "            ans.append(value)\n",
    "            i+=1\n",
    "        return ans\n",
    "    \n",
    "    else :\n",
    "        \n",
    "        factor =  (finalValue / initialValue) ** (1 / maxSteps) \n",
    "        i=1\n",
    "        \n",
    "        while i <= maxSteps :\n",
    "            value = initialValue * (factor ** i)\n",
    "            ans.append(value)\n",
    "            i+=1\n",
    "        \n",
    "        return ans \n",
    "        \n",
    "y_axis1 = decayAlpha(1000, 10, 10, 1)\n",
    "y_axis2 = decayAlpha(1000, 10, 10, 0) \n",
    "\n",
    "x_axis = [i for i in range(1,12)]\n",
    "\n",
    "\n",
    "plt.plot(x_axis, y_axis1 , label='exponential')\n",
    "plt.plot(x_axis, y_axis2 , label='linear'      )\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "#plt.savefig(\"qn22.png\", format=\"png\", dpi=1200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ea23a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kislayadityaoj/opt/anaconda3/lib/python3.9/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.size to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.size` for environment variables or `env.get_wrapper_attr('size')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.00653597, 0.00647061, 0.00666868,\n",
       "        0.00673604, 0.        ],\n",
       "       [0.        , 0.        , 0.00649414, 0.0064292 , 0.00666868,\n",
       "        0.00673604, 0.        ],\n",
       "       [0.        , 0.        , 0.01179507, 0.01157198, 0.01186244,\n",
       "        0.01219899, 0.        ],\n",
       "       [0.        , 0.        , 0.01620418, 0.01584956, 0.01618243,\n",
       "        0.01674287, 0.        ],\n",
       "       [0.        , 0.00279246, 0.01890877, 0.0185278 , 0.01911855,\n",
       "        0.02038092, 0.        ],\n",
       "       [0.        , 0.00279246, 0.02151859, 0.02111207, 0.02183702,\n",
       "        0.02312386, 0.        ],\n",
       "       [0.        , 0.00279246, 0.02151859, 0.02293415, 0.02367653,\n",
       "        0.02497992, 0.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def MonteCarloPrediction( Env , maxSteps , noEpisodes ,alph=0.01 ,policy=0 , gamma=0.99,   firstVisit=True):\n",
    "    # initializations\n",
    "    v = np.zeros(Env.size)\n",
    "    visited=np.zeros(Env.size)\n",
    "    v_r = np.zeros((noEpisodes,Env.size))\n",
    "    G_t = np.zeros(noEpisodes)\n",
    "    observation = Env.reset(seed=0)\n",
    "    \n",
    "    alpha= decayAlpha(alph, 0.001, noEpisodes , 0)\n",
    "    #algorithm\n",
    "    for e in range(noEpisodes):\n",
    "        observation = Env.reset(seed=0)\n",
    "        value=0\n",
    "        t = generateTrajectory( Env , policy , maxSteps)\n",
    "        \n",
    "        visited[:]=False\n",
    "        \n",
    "        for i , (s,action,reward,nex) in enumerate(t):\n",
    "            if visited[s] and firstVisit :\n",
    "                continue\n",
    "            else :\n",
    "                visited[s]=True\n",
    "            \n",
    "            G=0\n",
    "            j=i\n",
    "            while j<len(t):\n",
    "                G += ((gamma**(j-i))*(t[j][2]))\n",
    "                j+=1\n",
    "            \n",
    "            if s==5:\n",
    "                value=G\n",
    "            \n",
    "            v[s]+= alpha[e]*(G-v[s]) \n",
    "        G_t[e]=value\n",
    "        v_r[e]=v\n",
    "        \n",
    "    return v_r\n",
    "\n",
    "\n",
    "environment = make('RandomWalk' )\n",
    "observation = environment.reset(seed=0)\n",
    "MonteCarloPrediction( environment, 100,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d90afa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  0.99023276,  0.98247573,  0.97639253,  0.        ,\n",
       "       -0.02768894,  0.        ,  0.        ,  0.97158653, -0.0290686 ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def TemporalDifference( Env , noEpisodes ,alpha ,policy=0 , gamma=0.99):\n",
    "    # initializations\n",
    "    v = np.zeros(Env.size)\n",
    "    v_r = np.zeros((noEpisodes,Env.size))\n",
    "    observation = Env.reset(seed=0)\n",
    "    G_t = np.zeros(noEpisodes)\n",
    "    alpha= decayAlpha(alpha, 0.001, noEpisodes , 1)\n",
    "    \n",
    "    \n",
    "    #algorithm\n",
    "    for e in range(noEpisodes):\n",
    "        terminated = False \n",
    "        value=0\n",
    "        \n",
    "        while not terminated :\n",
    "            action = policy\n",
    "            observation, reward, terminated, truncated, info = environment.step(action)\n",
    "            td_target = reward\n",
    "            if not terminated :\n",
    "                td_target += gamma * v[info['log']['next_state']]\n",
    "                \n",
    "            td_error=td_target-v[info['log']['current_state']] \n",
    "            if info['log']['current_state'] == 5 :\n",
    "                value=td_error\n",
    "            \n",
    "            v[info['log']['current_state']]+=(alpha[e]*td_error)\n",
    "            info['log']['current_state']=info['log']['next_state']\n",
    "            \n",
    "        G_t[e]=value\n",
    "        v_r[e]=v\n",
    "        observation = Env.reset(seed=0)\n",
    "    return G_t\n",
    "\n",
    "\n",
    "environment = make('RandomWalk' , start=4)\n",
    "observation = environment.reset(seed=0)\n",
    "TemporalDifference( environment , 10 , 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22f848b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m observation \u001b[38;5;241m=\u001b[39m environment\u001b[38;5;241m.\u001b[39mreset(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      5\u001b[0m arr \u001b[38;5;241m=\u001b[39m TemporalDifference( environment , \u001b[38;5;241m500\u001b[39m , \u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m y_axis1\u001b[38;5;241m=\u001b[39m\u001b[43marr\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      8\u001b[0m y_axis2\u001b[38;5;241m=\u001b[39marr[:,\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m      9\u001b[0m y_axis3\u001b[38;5;241m=\u001b[39marr[:,\u001b[38;5;241m3\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "# question 2 - TD\n",
    "\n",
    "environment = make('RandomWalk' , start=2)\n",
    "observation = environment.reset(seed=0)\n",
    "arr = TemporalDifference( environment , 500 , 0.5)\n",
    "\n",
    "y_axis1=arr[:,1]\n",
    "y_axis2=arr[:,2]\n",
    "y_axis3=arr[:,3]\n",
    "y_axis4=arr[:,4]\n",
    "y_axis5=arr[:,5]\n",
    "\n",
    "x_axis = np.linspace(1,500,500)    \n",
    "\n",
    "# Plot the data\n",
    "plt.plot(x_axis, y_axis1, label='state-1')\n",
    "plt.plot(x_axis, y_axis2, label='state-2')\n",
    "plt.plot(x_axis, y_axis3, label='state-3')\n",
    "plt.plot(x_axis, y_axis4, label='state-4')\n",
    "plt.plot(x_axis, y_axis5, label='state-5')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.title('Value vs. Episode')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "\n",
    "plt.axhline(y = 0.16154172, color = 'blue', linestyle = 'dashed')\n",
    "plt.axhline(y = 0.33186436, color = 'orange', linestyle = 'dashed')\n",
    "plt.axhline(y = 0.504596, color = 'green', linestyle = 'dashed')\n",
    "plt.axhline(y = 0.65570089, color = 'red', linestyle = 'dashed')\n",
    "plt.axhline(y = 0.79724225, color = 'purple', linestyle = 'dashed')\n",
    "#plt.xscale('log')\n",
    "\n",
    "#plt.savefig(\"qn29.png\", format=\"png\", dpi=1200)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515dbe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 2 - MC\n",
    "\n",
    "environment = make('RandomWalk' )\n",
    "observation = environment.reset(seed=0)\n",
    "arr = MonteCarloPrediction( environment, 100,500,firstVisit=True)\n",
    "\n",
    "y_axis1=arr[:,1]\n",
    "y_axis2=arr[:,2]\n",
    "y_axis3=arr[:,3]\n",
    "y_axis4=arr[:,4]\n",
    "y_axis5=arr[:,5]\n",
    "\n",
    "x_axis = np.linspace(1,500,500)    \n",
    "\n",
    "# Plot the data\n",
    "plt.plot(x_axis, y_axis1, label='state-1')\n",
    "plt.plot(x_axis, y_axis2, label='state-2')\n",
    "plt.plot(x_axis, y_axis3, label='state-3')\n",
    "plt.plot(x_axis, y_axis4, label='state-4')\n",
    "plt.plot(x_axis, y_axis5, label='state-5')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.title('Value vs. Episode')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "\n",
    "plt.axhline(y = 0.16154172, color = 'blue', linestyle = 'dashed')\n",
    "plt.axhline(y = 0.33186436, color = 'orange', linestyle = 'dashed')\n",
    "plt.axhline(y = 0.504596, color = 'green', linestyle = 'dashed')\n",
    "plt.axhline(y = 0.65570089, color = 'red', linestyle = 'dashed')\n",
    "plt.axhline(y = 0.79724225, color = 'purple', linestyle = 'dashed')\n",
    "#plt.xscale('log')\n",
    "\n",
    "#plt.savefig(\"qn281.png\", format=\"png\", dpi=1200)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927a3685",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = make('RandomWalk' , start=2)\n",
    "observation = environment.reset(seed=0)\n",
    "arr = TemporalDifference( environment , 500 , 0.5)\n",
    "\n",
    "y_axis=arr\n",
    "\n",
    "\n",
    "x_axis = np.linspace(1,500,500)    \n",
    "\n",
    "# Plot the data\n",
    "plt.scatter(x_axis, y_axis, label='state')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.title('TD error vs. Episode')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('TD error')\n",
    "\n",
    "#plt.xscale('log')\n",
    "\n",
    "#plt.savefig(\"qn2155.png\", format=\"png\", dpi=1200)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59af560b",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = make('RandomWalk' )\n",
    "observation = environment.reset(seed=0)\n",
    "arr = MonteCarloPrediction( environment, 100,500,firstVisit=False)\n",
    "\n",
    "y_axis=arr\n",
    "\n",
    "\n",
    "x_axis = np.linspace(1,500,500)    \n",
    "\n",
    "# Plot the data\n",
    "plt.scatter(x_axis, y_axis, label='state')\n",
    "\n",
    "\n",
    "# Add labels and legend\n",
    "plt.title('MCEV Target vs. Episode')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('MCEV')\n",
    "\n",
    "\n",
    "#plt.xscale('log')\n",
    "\n",
    "#plt.savefig(\"qn214.png\", format=\"png\", dpi=1200)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555d1768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 2 - TD\n",
    "\n",
    "\n",
    "arr = np.zeros((500,7))\n",
    "              \n",
    "for i in range(20): \n",
    "    environment = make('RandomWalk' , start=2)\n",
    "    observation = environment.reset(seed=i)\n",
    "    arr = arr + TemporalDifference( environment , 500 , 0.5)\n",
    "arr = arr/20\n",
    "y_axis1=arr[:,1]\n",
    "y_axis2=arr[:,2]\n",
    "y_axis3=arr[:,3]\n",
    "y_axis4=arr[:,4]\n",
    "y_axis5=arr[:,5]\n",
    "\n",
    "x_axis = np.linspace(1,500,500)    \n",
    "\n",
    "# Plot the data\n",
    "plt.plot(x_axis, y_axis1, label='state-1')\n",
    "plt.plot(x_axis, y_axis2, label='state-2')\n",
    "plt.plot(x_axis, y_axis3, label='state-3')\n",
    "plt.plot(x_axis, y_axis4, label='state-4')\n",
    "plt.plot(x_axis, y_axis5, label='state-5')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.title('Value vs. Episode')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "\n",
    "plt.axhline(y = 0.16154172, color = 'blue', linestyle = 'dashed')\n",
    "plt.axhline(y = 0.33186436, color = 'orange', linestyle = 'dashed')\n",
    "plt.axhline(y = 0.504596, color = 'green', linestyle = 'dashed')\n",
    "plt.axhline(y = 0.65570089, color = 'red', linestyle = 'dashed')\n",
    "plt.axhline(y = 0.79724225, color = 'purple', linestyle = 'dashed')\n",
    "#plt.xscale('log')\n",
    "\n",
    "plt.savefig(\"qn283.png\", format=\"png\", dpi=1200)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cd531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.zeros((500,7))\n",
    "              \n",
    "for i in range(20): \n",
    "    environment = make('RandomWalk' )\n",
    "    observation = environment.reset(seed=i)\n",
    "    arr += MonteCarloPrediction( environment, 100,500,firstVisit=True)\n",
    "arr = arr/20\n",
    "\n",
    "y_axis1=arr[:,1]\n",
    "y_axis2=arr[:,2]\n",
    "y_axis3=arr[:,3]\n",
    "y_axis4=arr[:,4]\n",
    "y_axis5=arr[:,5]\n",
    "\n",
    "x_axis = np.linspace(1,500,500)    \n",
    "\n",
    "# Plot the data\n",
    "plt.plot(x_axis, y_axis1, label='state-1')\n",
    "plt.plot(x_axis, y_axis2, label='state-2')\n",
    "plt.plot(x_axis, y_axis3, label='state-3')\n",
    "plt.plot(x_axis, y_axis4, label='state-4')\n",
    "plt.plot(x_axis, y_axis5, label='state-5')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.title('Value vs. Episode')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "\n",
    "plt.axhline(y = 0.16154172, color = 'blue', linestyle = 'dashed')\n",
    "plt.axhline(y = 0.33186436, color = 'orange', linestyle = 'dashed')\n",
    "plt.axhline(y = 0.504596, color = 'green', linestyle = 'dashed')\n",
    "plt.axhline(y = 0.65570089, color = 'red', linestyle = 'dashed')\n",
    "plt.axhline(y = 0.79724225, color = 'purple', linestyle = 'dashed')\n",
    "#plt.xscale('log')\n",
    "\n",
    "#plt.savefig(\"qn281.png\", format=\"png\", dpi=1200)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f54c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8570306d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
